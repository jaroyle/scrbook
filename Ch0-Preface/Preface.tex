Stuff on hierarchical models and how great those are.

Bayesian and likelihood analysis..... We don't care, and neither
should you.

\section{Computing}

Emphasis on doing things in the 
R programming language  - A link to CRAN or whatever. Reference some
other books about using R and so forth. Which packages do we use? (see
Appendix). 

We do Bayesian analysis almost exclusively in the BUGS language, using
WinBUGS and JAGS. Mostly we are transitioning to use of JAGS but we
still like WinBUGS a lot. Oold habits die hard..... WinBUGS is not in
active develpment anymore, but JAGS is. So is OpenBUGS but we didn't
want to use all of them (whats the point?). We love the BUGS language
because, as Marc Kery said, it ``frees the modeler in you''.
If you can express your model algebraically, in the BUGS language,
then JAGS or WinBUGS or OpenBUGS will do the MCMC for you. Thats
pretty handy.

We do a limited amount of developing our own custom MCMC algorithms
(see chapt. XXXX) which we think is really handy for certain
problems. In fact, there are problems that WinBUGS or JAGS can't do,
and so we have had to develop our own custom algorithms (e.g.,
Sollmann et al. 2012; Chandler and Royle 2013). This is really handy
because you can then exploit large linux or windows clusters to
distribute your computing efficienctly. There are R packages for that
(snowfall XXXX and others). 

We do a fair amount of likelihood analysis in this book. Mostly we
rely on the R package \mbox{\tt secr} \citep{efford_etal:2009euring}
but we also show how to compute the likelihood for certain specific
models in a few chapters.

\section{R package scrbook}

We have an R package that comes with the book. Almost all analyses are
in there -- R/BUGS scripts, etc....
The purpose of the package is  not meant to be general-purpose and
flexible software for doing SCR models but, rather, a set of examples
and templates to see how specific things are done.   Because we use so
many different software packages and computing platforms, we think its
impossible to put all of what is convered in this book into a single
integrated package. 


A commented Gibbs sampler written
in \R~is available in the accompanying \R~package \scrbook~(see
\texttt{?scrIPP}). This function is not meant to be an all purpose
tool for fitting SCR models using MCMC---instead, it is presented so
that interested readers can better understand the computational
aspects of the problem and can modify it for their purposes.



\section{Organization of This Book}

Comment on the 4 parts of the book........

In the following chapters we develop a comprehensive synthesis and extension of
spatial capture-recapture models.
Roughly the first third of the book is introductory material --
In Chapt. \ref{chapt.glms} we provide the basic analysis tools to understand and
analyze SCR models - namely generalized linear models (GLMs) with random effects, and their
analysis in {\bf R} and {\bf WinBUGS}.  Because SCR models represent extensions of
basic closed population models, we cover ordinary closed population
models in Chapt. \ref{chapt.closed} wherein, along with Chapts. \ref{chapt.scr0} and \ref{chapt.poisson-mn}
\footnote{might ought to put Modeling Encounter Probability
  as chapter 5 instead}, provides the basic introduction
to capture-recapture models and their spatial extension.
We will see that
SCR models are a
conceptual and technical intermediates between the class of models referred to as
model $M_h$, and so-called
individual covariate models.
We develop technical tools for likelihood (Chapt. \ref{chapt.mle})
and Bayesian analysis (Chapt. \ref{chapt.mcmc}).
The middle part of the book expands set of models that we can deal with to include alternative
observation models related to the type of encounter device (Chapt. \ref{chapt.poisson-mn}), models for encounter probability
(Chapt. \ref{chapt.covariates}), [should include search-encounter
models right after Poisson-mn type models?] and provides basic tools
for model fit and selection (Chapt. \ref{chapt.gof}).
[should include the design chapter right here].
Finally in the last third of the book we address more advanced stuff including modeling
space usage in the encounter process (Chapt. \ref{chapt.ecoldist}), modeling state-space covariates, covariates
that affect density, (Chapt. \ref{chapt.state-space}), open population models (Chapt. \ref{chapt.open}),
models that include unmarked individuals either entirely (Chapt. \ref{chapt.scr-unmarked})
or partially marked samples (Chapt. \ref{chapt.partialID}).

In Chapter XXXX We cover a mish-mash of ideas: using telemetry data, multiple encounter methods, alternative
point-process models, and other topics that are useful but that are not fully developed or that we don't have
room for in this book.





\hl{From Ch1b:}

In our experience, students in ecology and even many established
scientists simply cannot separate what they need to do from how to do
it.  They cannot distinguish clearly (either conceptually or actually)
the difference between the model for their data, and the actual
procedure of how to estimate parameters of that model, or make
predictions - ie., how to do the calculations. Sometimes this issue
raises itself in an email from some hapless grad student wondering
``what is the right statistical test for this type of data?''  In a
sense it is this view that drives our approach to developing elements
of this book.

In contemporary statistical ecology, models and methods are sometimes
obscured by named procedures often that are completely uninformative,
the technical details of which hide in obscurity in some black boxes
such as MARK, PRESENCE, DISTANCE, etc., known only by the few
specialist experts in the field. While it is sometimes convenient to
refer to a type or class of models by a name (logistic regression or
even ``model Mh'') in order to emphasize a broad concept or
methodological area, this is only useful if the fundamental
statistical and mathematical structure underlying that name is
clear. As such, we try to focus on model development and keep the
model development distinct from how to combine our data with the model
to produce estimates and so forth. We talk a lot about hypothetical
data we wish we could observe - complete data sets - data sets as if
$N$ were known, etc.. We talk about the model in precise terms and
then break down various ways for analyzing the model either using
likelihood methods or Bayesian methods or some black-box that does one
or the other.

To fit models, we rely heavily on the various implementations of the
{\bf BUGS} language including {\bf WinBUGS} \citep{lunn_etal:2000},
{\bf JAGS} \citep{plummer:2003}
 and {\bf OpenBUGS} \citep{thomas_etal:2006}. We really like
the {\bf BUGS} language, not merely  as a computational device for
fitting models but because it emphasizes
understanding of what the model is and fosters understanding how to
build models - as Kery XYZ XYZ says ``it frees the modeler in you.''  (direct
citation for this would be nice).  However, in addition to using the
{\bf BUGS} language and its various implementations, we also develop our own
{\bf R} code both for doing MCMC
and maximum likelihood, for which we also use the R
package \mbox{\tt secr} \citep{efford:2011}. In addition, we have
created an {\bf R} package to go with this book, \mbox{\tt scrbook},
which contains the data sets, {\bf R} and {\bf BUGS} scripts, and {\bf
  R} code for doing summary analyses, and some likelihood and MCMC
functions written solely in {\bf R}.


\subsection{Who should read this book}

This book is not a book about Bayesian analysis, not a book about
hierarchical models, not a book about capture-recapture, and not about
programming in R. In a sense though, our book integrates elements of
all of these things into what we hope is a coherent package for
analyzing data from this enormous class of data collection methods
that produce spatially-explicit capture-recapture data.   As such, we
expect that people have a basic understanding of statistical models
and classical inference (What is frequentist inference? what is a
likelihood? Generalized linear model? Generalized linear mixed
model?),
{\bf R} programming,
 Bayesian analysis (what is s a prior distribution and a
posterior distribution?),
and maybe even a little bit
of Bayesian
computation (MCMC and perhaps the BUGS language).
The ideal candidate for reading this book has basic knowledge of these
topics. However, we do provide introductory chapters on the necessary
components which we hope can serve as a brief and cursory tutorial for
those who might have only limited technical knowledge, e.g., many
carnivore biologists who implement field sampling programs but do not
have extensive experience analyzing data.

