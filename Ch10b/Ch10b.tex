\chapter{
Modeling Space Usage: 
Integrating Resource Selection Information with 
Spatial Capture-Recapture
  Models}

\markboth{Chapter XXX}{}
\label{chapt.rsf}


\vspace{.3in}

Up to this point we have developed many specific variations of
relatively simple SCR models. They included various observation
models, and various types of covariates including behvioral responses
and other things that should affect detection probability.
That said, the models remain pretty basic in the sense that they imply
relative simple models of how individuals use space (section XXXXXX) and how
individuals are distributed in space.

SCR is the shit

RSF is the shit

SCR + RSF? !!!!

Here we show how to integrate standard RSF type data into SCR models
to model space usage expcliitly. This produces asymmetric, irregular
and non-stationary home ranges, and allows us to make formal
inferences about factors that influence home range geoemetry and
morphology directly from SCR data.

First we describe a model for space usage and one for encounter
probability that are consistent with one another.
This allows us to define a general likeleihood function that is the
product of the two pieces -- if they're independent. 
Then we see if we don't have RSF data we have an ordinary SCR model
simply with a spatial covariate on encounter probability. We can thus
estimate the RSF directly from SCR data, or we can integrate telemetry
data directly into the SCR model. 

In our formulation we estimate the s[i] from the observed telemetry
data, just as a convenience, but this wouldn't be necessary.
Also we assume the data are independent pieces but if some of the SCR
individuals are the same as the telemetered individuals then we should
probably account for that explicitly. So right now we pretend we don't
know anything about the telemtered guys in terms of their capture
history. So they don't contribute to information about baseline
encounter probability, just to estimates of the other encounter model
parameters. 



\section{Model Formulation}

No landscape on your computer is continuous.

RSF model:
 telemetry fixes produces n(i,j) = number of fixes for individual i in
 pixel j.  The standard RSF model is that, conditional on the total
 number of fixes, these are multinomial random variables with
 probabilities
\[
 \pi_{i,j} = \frac{ exp( -\beta z(x) ) }{ \sum_{x} exp(-\beta z(x))} 
\]
this is the same as saying
\[
 n(i,j) \sim Poisson( \lambda_{ij})
\]
where
\[
 log(\lambda_{ij}) = \beta_{0}  + \beta_{1} z(x)
\]
Intercept here is completely fixed. We decide on that. How many fixes
do we wish to have?



So the key to combing RSF data with SCR data is to think about this
Poisson model. In SCR data the total encounter frequency is a random
variable and, in fact, we only observe the event $n_{ij}>0$ but it
should have the same mean, just a different intercept. Thus when we
observe $y_{ijk} = 1$ this occurs if the individual visited the pixel
containing a trap, i.e.,  $m_{ij}>0$, and we detected it. in this
construction $m_{ij}$ is a ``detectable'' visit to a pixel, say of an
individual wandering in the vicinity of a trap or a trail that is
sampled. 
We imagine a hierarchy like this:
\[
m_{ij} \sim Bin(n_{ij}, p_{0})
\]
therefore
\[
m_{ij} \sim Poisson( \lambda_{ij} p_{0} )
\]
and
we observe the binary event $y_{ijk} = 1$ if $m_{ijk}>0$. Therefore 
this occurs with probability 
\[
 p_{ij} = 1-exp(- \lambda_{ij} p_{0} ) 
\]
we see that $p_{0}$ and a baseline rate of use  $exp(\beta_{0})$ are
all balled up together which makes sense. 
think of this as follows: we have some detector sitting there in a
pixel and we sample continuously and $p_{0}$ is the rate of encounter
given that an individuals visits a pixel. 




one thing about this is if you have no covariates at all then
the telemetry RSF function is proportional exactly to the SCR 
detection model? Well that really isn't quite true. But if 
we use a half-normal detection model then , in that case, 
\[
p_{ij} \propto RSF
\]
but we can't just set $p_{ij} = RSF$ because RSF's add to 1 over space
but $p_{ij}$ don't. 



\section{Maximum likelihood estimation}
\label{sec.mle}

Here we outline a standard method of parameter estimation based on
marginal likelihood. That is, the likelihood in which the latent
variables ${\bf s}$ are removed by integration \citep{borchers_efford:2008}.
The individual- and trap-specific observations have a binomial
distribution conditional on the latent variable ${\bf s}_{i}$:

\begin{equation}
	y_{ij}| {\bf s}_{i} \sim \mbox{Bin}(K, p_{\theta}(d_{lcp}({\bf x}_{j},{\bf s}_{i};\theta_{2}); \theta_{0}, \theta_{1})
\label{mle.eq.cond-on-s}
\end{equation}

{\flushleft where} we have indicated the dependence of $p_{ij}$ on the parameters
${\bm \theta}$, and also $d_{lcp}$ which
itself depends on $\theta_{2}$, and the latent variable ${\bf s}$.
%The parameters
%${\bm \theta}$ include whatever parameters are involved in the
%cost-weighted distance function, i.e., at least $\theta_{2}$ from
%Eq. \ref{eq.cost}.
For the random effect we have ${\bf s}_{i} \sim  \mbox{Unif}({\cal
  S})$.
The joint distribution of the data for individual $i$ is the product
of $J$ binomial terms (i.e., contributions from each of $J$ traps):
$  [{\bf y}_{i} | {\bf s}_{i} , \theta] =
  \prod_{j=1}^{J} \mbox{Bin}(K, p_{\theta}({\bf x}_{j},{\bf s}_{i}) )$.
%This assumes independence of capture in each trap.
%Conditional on
%${\bf s}_{i}$ this is reasonable in most applications in our view.
 The so-called marginal likelihood is computed by removing
${\bf s}_{i}$, by integration,  from the conditional-on-${\bf s}$
likelihood and regarding the {\it marginal} distribution of the data
as the likelihood. That
is, we compute:

\[
  [y|{\bm \theta}] =
\int_{{\cal S}}  [ {\bf y}_{i} |{\bf s}_{i},{\bm \theta}] g({\bf s}_{i}) d{\bf s}_{i}
\]

{\flushleft where}, under the uniformity assumption, we have
$g({\bf s}) = 1/||{\cal S}||$.
The joint likelihood for all $N$ individuals, 
is the product of $N$ such terms:

\[
{\cal L}({\bm \theta} | {\bf y}_{1},{\bf y}_{2},\ldots, {\bf y}_{N}) = \prod_{i=1}^{N}
[{\bf y}_{i}|{\bm \theta}]
\]

Technical details for computing the likelihood and obtaining the MLEs
are given in Appendix 2 where we provide an ${\bf R}$ function
to evaluate the likelihood and obtain the MLEs.
A key practical detail is that the likelihood here is formulated in
terms of the parameter $N$, the population size for the landscape
defined by ${\cal S}$. Given ${\cal S}$, density
is
computed as $D({\cal S}) = N/||{\cal S}||$. In our simulation study
below we report $N$ as the two are equivalent summaries of the data
set once ${\cal S}$ is defined.


\section{Illustration}

In this section we provide examples that we think are typical of how
cost-weighted distance models can be used in real capture-recapture
problems.  We define a $20 \times 20$ pixel landscape with 
extent = $[0.5, 4.5] \times [0.5, 4.5]$.  
%We define this landscape by
%a single covariate for determing the cost function, and we consider
%two specific covariates.
%purposes of our example, as a coarse landscape covariate, with pixels
%having some arbitrary scaling say, a $2 \times 2$ km resolution. Thus,
%the raster defines a landscape of $40 \times 40$ km and we suppose
We suppose that 16 camera traps are established at the integer coordinates
$(1,1), (1,2), \ldots, (4,4)$. We could think of this as a landscape
within which we're studying a population of ocelots, lynx or some
other cat.

For our analyses, cost is characterized by a single covariate 
and we consider two specific cases. First is an increasing trend from
the NW to the SE (''systematic landscape''), where $z(x)$ is defined as
$z(x) = r(x) + c(x)$ where $r(x)$ and $c(x)$ are just the row and
column, respectively, of the landscape.  This might define something
related to distance from an urban area or a gradient in habitat
quality due to land use, or environmental conditions such as
temperature or precipitation gradients.  In the second case we make up
a covariate by generating a field of spatially correlated noise to
emulate a typical patchy habitat covariate (''patchy landscape'') such as
tree or understory density. The two covariates are shown in
Fig. \ref{ecoldist.fig.raster100}, along with a sample realization of
$N=100$ individuals (left panel only).  For both covariates we use a
cost function in which transitions from pixel ${\bf x}$ to ${\bf x}'$
is given by:

\[
 log(cost({\bf x},{\bf x}'))=  \theta_2 \frac{z({\bf x}) + z({\bf x}')}{2}
\]

{\flushleft where} $\theta_2 = 1$ for our simulation.
When $\theta_2=0$ the
model reduces to one in which the cost of moving across each pixel is
constant, and therefore distance is Euclidean.








\section{Summary and Outlook}


All published applications of SCR models to date have been based on models for the
encounter probability that are functions of the standard Euclidean
distance between individuals and traps. The obvious limitations are
that it is unaffected by landscape or habitat structure and implies
stationary, isotropic and symmetrical home ranges. These are standard
criticisms of the basic SCR model as universally applied in
practice. However, it is not a relevant criticism of the basic
conceptual formulation of SCR models, because, as we have
demonstrated, one can modify the Euclidean distance metric to
accommodate more realistic space usage considerations.  Following
\citet{royle_etal:2012ecol},
we demonstrated how to use
minimum cost-weighted distance (i.e., ``least-cost
path'') between points, and where ``cost'' is characterized by one or
more spatially explicit covariates that are believed to influence
movement or space-usage of individuals.

How animals use space and therefore how distance to a trap is
perceived by individuals is not something that can ever be known. We
can only ever conjure up models to describe this phenomenon and fit
those models to limited data on a sample of individuals during a
limited amount of time.  Here we have shown that there is hope to
estimate parameters, from capture-recapture data, that describe how
animals use space and thereby allow for irregular home range geometry
that is influenced by landscape structure.

Not surprisingly, our simulation study demonstrated
(Table 2) that the MLE of model parameters is
approximately unbiased in moderate sample sizes. Moreover, the effect
of ignoring ecological distance and using normal Euclidean distance in
the model for encounter probability, has the logical effect of causing
negative bias in estimates of $N$.  We expect this because the effect
is similar to failing to model heterogeneity. i.e., if we mis-specify
``model $M_h$'' \citep{otis_etal:1978} with ``model $M_0$''
\citep{otis_etal:1978} then we will expect to under-estimate $N$. So
the effect of mis-specifying the ecological distance metric with a
standard homogeneous Euclidean distance has the same effect. As a
practical matter, it stands to reason that many previous applications
of SCR models based on homogeneous distance metrics have under-stated
density of the focal population.

In our view, this bias is not really the most important reason to
consider models of ecological distance. Rather, inference about the
structure of ecological distance is fundamental to many problems in
applied and theoretical ecology related to modeling landscape
connectivity, corridor and reserve design, population viability
analysis, gene flow, and other phenomena.  Our new model allows
investigators to evaluate landscape factors that influence movement of
individuals over the landscape from non-invasively collected
capture-recapture data.  Therefore SCR models based on ecological
distance metrics might aid in understanding
aspects of space usage and movement in animal populations and, ultimately, in addressing conservation-related problems such as corridor design.

We considered inference for ecological distance models based on
marginal likelihood \citep{borchers_efford:2008}
(see Chapt. \ref{chapt.mle}).
In principle,
Bayesian analysis does not pose any unique challenges for this new
class of models, except that computing the cost-weighted distance is
computationally intensive.  So, having to do this at each iteration of
an MCMC algorithm may be impractical using existing algorithms.  A
related issue is that the size of the raster slows things down. For
very large rasters, even likelihood analysis can be computationally
challenging and methods for efficient calculation of the ecological
distance given the raster covariate(s) and parameters might be needed.





























