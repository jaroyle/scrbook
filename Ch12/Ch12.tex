\chapter{SCR Models for Open Populations}
\markboth{Chapter 12 }{}
\label{chapt.open}

\vspace{0.3cm}


\section{Introduction}

All of the previous chapters have focused on closed population models
for estimating density, in this chapter, we develop a framework for
inference about data from spatial capture recapture studies for
demographically open populations.  There are a number of reasons why
modeling open populations is of interest to researchers.  Probably the
most important reason because natural populations experience mortality
and recruitment over time.  Modeling parameters such as survival,
recruitment, and home range center movement can allows us to better
understand population dynamics.  For example, survival probability is
a key demographic parameter driving populations
\citep{saether_bakke:2000}.  For the first time, we can fully
integrate the movement of individuals onto and off of the trap array
with their encounter histories to simultaneously estimate density,
survival, and recruitment in a spatial model.  For many species, such
as those that are rare or not often observed by researchers, we can
finally make inference about survival and recruitment without having
to physically capture individuals.  Additionally, another reason
extending our SCR models to open populations arises purely from a
sampling perspective.  We often need longer time periods to sample
rare or elusive species to ensure that enough captures and recaptures
are produced.  This extended time frame can quickly lead to violations
in the assumption of population closure.  For example, the European
wildcat study that was presented in chapter XXX insert ref XXX was
conducted over a year long period.  While the researchers in that
study used a closed population, they did model variation in detection
as a function of time.  Another approach would have been to use an
open population model (the spatial capture recapture open models had
not been developed at the time of the wildcat study, so we'll forgive
the authors for not having used this more appropriate model).

The modeling framework we will develop in this chapter is based on a
formulation of Cormack-Jolly-Seber (CJS) and Jolly-Seber (JS) type
models \citep{cormack:1964, jolly:1965, seber:1965} that are amenable
to modeling individual effects, including individual covariates.
There is a long history of use of these models in fisheries, wildlife,
and ecology studies \citep{pollock_et al:1990, lebreton_etal:1992,
  pradel:1996, williams_etal:2002, schwarz_arnason:2005,gimenez:2007}.
Additionally, there have been many modifications and developments of
the CJS and JS models including dealing with transients, multi-state,
and spatially implicit models.


Before extending these models to our SCR framework, let's first look
at the basic assumptions of both models.  No tag (or mark) loss is
assumed in both models.  If a marked animal losses his/her tag or
mark, then that animal cannot be recaptured and this could appear as
though the animal has died.  Thus, to maintain unbiased estimates of
survival, no tag or mark loss is important.  Additionally, capture and
release should be instantaneous (or as close as possible), otherwise
the time interval between capture occasions could differ for
individuals and that would result in individual heterogeneity of
survival.  Individuals must also be recorded accurately.

In the standard CJS models, it is also assumed that all emigration
from the study area is permanent and that capture and survival
probabilities are constant within each sample occasion and group.  A
group can be created based on sex, age, area, etc.  In the CJS
formulation of the model, we condition on the captured individuals,
thus we estimate only the probability of recapture and the survival
rates.  Here, survival is considered the ``apparent'' survival because
emigration and mortality are confounded within the model, thus
apparent survival is always estimated lower than true survival when
emigration is not zero.  In the JS version of the model, we do not
condition on marked individuals.  Thus we can estimate survival like
we do in the CJS, but now we can also model recruitment (new
individuals coming into the population) and the total
abundance/density of the population.  Estimating more parameters does
require a few more assumptions including that all individuals in the
population have the same probability of capture.  Under a ``robust
design'' (\citep{pollock:1982}, which we will demonstrate in this
capture, we can estimate heterogeneity in capture probabilities.  To
that extent, we can envision the data as arising from repeated
sampling over seasons or years (or {\it primary} periods) within which
one or more samples (e.g., nights) might be taken ({\it secondary}
periods).  Comparing this with all of our previous work, the sample
intervals (e.g., trap nights, weeks, etc. ) described in the closed
population chapters are equivalent to {\it secondary} periods).


\section{CJS models}

%%% Beth, while CSJ models are in some ways less complex than JS
%%% models it might make for a more natural flow of things to have JS
%%% models first -- because they are most naturally discussed as the
%%% extension of SCR0 and other models, whereas the CJS is then a
%%% simplification of those models , but not at all an extension of
%%% SCR0.

There are essentially two ways to fit these models, using either a
multinomial approach \citep{lebreton_etal:1992} or a state-space
likelihood approach \citep{gimenez:2007, royle:2008}.  Multi-state
models have been used to estimate survival and movement in CJS models
using spatial or geographic location as a state (see
\cite{kery_schaub:2011} for a review of these models using WinBUGS).
Building on the state-space and multi-state CJS models, we can
explicitly model individual movement into the CJS models as an
individual covariate model \citep{royle_indcov:2007}.

To extend SCR models to open populations, we adopt a hierarchical
parameterization of the JS models in which the observation model is
described conditional on the latent state variables $z(i,t)$ -- the
“alive state” – which describe whether individual $i$ is
alive ($z(i,t)=1$) or not ($z(i,t)=0$) during each of $t=1,2,\ldots,T$
{\it primary} periods.  We may consider the same basic encounter
models as described previously (i.e., Poisson, Bernoulli, or
multinomial). In particular, let $y_{ijkt}$ indicate the observed
encounter data of individual $i$ in trap $j$, during interval
(sub-sample) $k=1,2,\ldots,K$ and primary period $t$. We note that in
some cases we may have intervals ($K=1$) which correspond to the
design underlying a standard CJS or JS models whereas the case $K>1$
corresponds to the ``robust design'' (\citealt{pollock:1982}).  The
Poisson observation model, specified conditional on $z(i,t)$, is:
 \[
  y_{ijkt}|z(i,t) \sim
\mbox{Pois}(\lambda_0 g_{ij} z(i,t)). 
\] 
Thus, if individual $i$ is alive at time $t$ ($z(i,t)=1$), then the observations are Poisson as before. Conversely, if the
individual is not alive ($z(i,t)=0$), then the observations must be
fixed zeros with probability 1.   In the CJS formulation, we will condition on first capture which means that $z(i,t}$ will 
be 1 when $t$ is the first primary period of capture.  We can denote this $z(i, t_first)$  XXX still working on best notation 
for first capture XXXX.  This ensures that each individual is alive upon entering the model.   Modeling time-effects either 
within or across primary periods
is straightforward. For that, we define $\lambda_{0} \equiv
\lambda_{0}(k,t)$ and then develop models for
$\lambda_{0}(k,t)$ as in our closed SCR models (we note that
trap-specific effects could be modeled analogously).

Instead of allowing $z(i,t}$ to be independent for each year, we
describe the ''alive state" at time $t$ for each individual as a
function of the state at the previous time step $t-1$.  The initial
state is described the same way as we have done in our closed
population models, by:
\[
 z(i,1) \sim \mbox{Bern}(\psi)
\]
and to model the transition of individual states from $t$ to $t+1$ for
all $t >2$ we have
\[
 z(i,t) \sim \mbox{Bern}( \phi z(i,t-1)).
\] 
Thus, if $z(i,1)=1$, then the individual may survive with probability
$\phi$ to time $t=2$ and so forth.  Once an individual leaves the
population (i.e., $z(i,t) = 0$), there is no mechanism for the
individual to return.

In the CJS model we are not estimating $N$, so we do not incorporate
any data augmentation here.  This conveniently makes the model run
faster too!


\section{Migratory fish example}

In stream networks, technology such as passive integrated transponders
(PIT) and the placement of PIT antennas along the stream mimics the
type of spatial data collected in terrestrial passive arrays such as
camera traps, hair snares, acoustic recording devices, etc.  The
difference is that for fish and aquatic species, the stream constrains
the movement of individuals to a linear network.  Here, we demonstrate
the CJS model to evaluate survival and movement of migratory fishes in
a North Carolina river using an American shad \it{Alosa sapidissima}
example.  Using a resistance board weir near the river mouth, 317 fish
were tagged with passive integrated transponders (PIT) in the spring
of 2010. An array of 7 upstream PIT antennas passively recaptured
individuals during upstream and downstream migrations.  The number of
times each fish passed over the antenna was recorded and summarized
each week for 12 weeks.  Thus, the dimensions of the data are 317
individuals by 7 antennas by 12 sample occasions. Individuals can
encounter any antenna any number of times during the week, which means
we just sum the encounters over the week and eliminate any need for
explicit secondary occasions in the model The result is a 3-D array
instead of a 4-D array.  Given the structure of the encounters, we use
a Poisson encounter model in this example.  Since we condition on
first capture, it is necessary for the model that we record the week
when each fish was tagged.

\begin{verbatim}
XXXX Clean up initial code for data entry XXXXX
library(reshape)

# Constants:
M <- 317       # Number of individuals
T <- 12     # Number of periods (weeks)
nantenna <- 7  # weir, 6 antennas
antenna.loc <- c(3,7,12,44,56,72,77)  # antenna locations
xl <- 0     # lower boundary, river mouth
xu <- 82    # upper boundary, Atkinson Mill Dam


# Input and format data matrix:
AS10 <- read.table("AS10.txt" ,header=T)
melted.rkm <- melt(AS10, id=c("TagID","RKM"))
tagid.week <- cast(melted.rkm, TagID ~ RKM ~ value, fill=0, length)
y <- tagid.week
first=read.csv("firstcap.csv")

sink("ModelCJS.txt")
cat("

model {

# Priors

sigma ~ dunif(0,80)  
sigma2 <- sigma*sigma
lam0 ~ dgamma(0.1, 0.1)  
phi ~ dunif(0, 1)   # Survival (constant across time)
tauv~dunif(0, 30)
tau<-1/(tauv*tauv)

 
# Code can be improved, Right now has same code for first[i] and t except for z

for (i in 1:M){        
  z[i,first[i]] ~ dbern(1)       
  S[i,first[i]] ~ dunif(0,50)  
  
for(j in 1:nantenna) {
	  D2[i,j,first[i]] <- pow(S[i,first[i]]-antenna.loc[j], 2)   
       lam[i,j,first[i]]<-  lam0*exp(- D2[i,j,first[i]]/(2*sigma2))
       tmp[i,j,first[i]] <- lam[i,j,first[i]]   # z[i,first[i]]* not needed here because z=1 when first entering
         y[i,j,first[i]] ~ dpois(tmp[i,j,first[i]])
      }

   for (t in first[i]+1:T) {
	          S[i,t] ~ dunif(xl, xu)
         for(j in 1:nantenna) {
		        D2[i,j,t] <- pow(S[i,t]-antenna.loc[j], 2)   
               lam[i,j,t] <- lam0 * exp(-D2[i,j,t]/(2*sigma2))
	           tmp[i,j,t] <- z[i,t]*lam[i,j,t]
		         y[i,j,t] ~ dpois(tmp[i,j,t])
		 }
 	   phiUP[i,t] <-  z[i,t-1]*phi     
	       z[i,t] ~ dbern(phiUP[i,t])
	}  
	}  
}  

",fill = TRUE)
sink()

data1<-list(y=y, first=first, M=M, T=T, xl=0, xu=80, nantenna=nantenna, antenna.loc=antenna.loc)

z=matrix(NA, 317, 12)
for(i in 1:317){
for(t in first[i]:12){
z[i,t] <-1
}
}

inits =  function() {list(z=z,phi=runif(1,0,1), lam0=runif(1,0,2), tauv=runif(1,10, 20), sigma=runif(1,0,10)) }

parameters <- c("sigma", "phi", "lam0")
                                                          
library("rjags")

out1 <- jags.model("modelCJS.txt", data1, inits, n.chains=3, n.adapt=500)
out2CJS <- coda.samples(out1,parameters,n.iter=20000)

> summary(out2JS)

Iterations = 501:20500
Thinning interval = 1 
Number of chains = 3 
Sample size per chain = 20000 

1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:

        Mean      SD  Naive SE Time-series SE
lam0  1.8022 0.04776 0.0001950      4.762e-04
phi   0.7549 0.01269 0.0000518      6.657e-05
sigma 9.3645 0.14680 0.0005993      1.542e-03

2. Quantiles for each variable:

        2.5%    25%   50%    75%  97.5%
lam0  1.7105 1.7695 1.801 1.8341 1.8977
phi   0.7293 0.7465 0.755 0.7635 0.7793
sigma 9.0855 9.2637 9.362 9.4623 9.6583

\end{verbatim}

Because our primary periods in this model are defined as weeks, our
survival rate is actually the weekly survival.  In this case, our
posterior mean estimate for $\phi$ was 0.75, suggesting that most fish
have a low survival probability.  This could is likely due to the fact
that the migration upstream can be quite energetically taxing.
Additionally, the CJS model is only estimating the 'apparent' survival
and some fish may have left the stream temporally or permanently.  The
other parameter of interest is $\sigma$, the movement parameter.  Our
system here is linear, so we do not think of fish as having a home
range radius in this system.  However, $\sigma$ can still inform us
about the linear distance fish are moving.  XXXX should I convert
sigma to a linear movement distance - like a 95 percent distance
moved?? XXX



\section{Spatial Jolly-Seber Models}

To parameterize the JS models, we can start with the same set up as
the CJS model.  Again, we describe the Poisson observation model,
specified conditional on $z(i,t)$, as:
 \[
  y_{ijkt}|z(i,t) \sim
\mbox{Pois}(\lambda_0 g_{ij} z(i,t)). 
\] 
Thus, if individual $i$ is alive at time $t$ ($z(i,t)=1$), then the
observations are Poisson as before.  Conversely, if the individual is
not alive ($z(i,t)=0$), then the observations must be fixed zeros with
probability 1.

Survival and recruitment in the open population are manifest in a
model for the latent state variables $z(i,t)$ describing individual
mortality and recruitment events.  An important aspect of the
hierarchical formulation of the model that we adopt here is that the
model for the state variables is described conditional on the total
number of individuals ever alive during the study (a parameter which
we label $N$) based on $T$ periods, as in \cite{schwarz1996gma}.  Data
augmentation induces a special interpretation on the latent state
variables $z(i,t)$.  In particular, ``not alive'' includes individuals
that have died, or individuals that have not yet been recruited.
Using this formulation simplifies the state model and also allows it
to be implemented directly in the JAGS software \cite {royle:book}.
For example, considering the case $T=2$, the state model is composed
of the following two components: First the initial state is described
by:
\[
 z(i,1) \sim \mbox{Bern}(\psi)
\]
and then a model describing the transition of individual states from
$t=1$ to $t=2$:
\[
 z(i,2) \sim \mbox{Bern}( \phi z(i,1)  + \gamma (1-z(i,1)) ).
\] 
Thus, if $z(i,1)=1$, then the individual may survive with
probability $\phi$ whereas, if $z(i,1)=0$, then the
``pseudo-individual'' may be recruited with probability $\gamma$. 

We can then generalize this model for $T>2$ time periods and allow survival and
recruitment to be time dependent.  Initialize the 
model for time $T=1$ as we have done above 
and then the model describing the transition of individual states from
$t$ to $t+1$ is:
\[
 z(i,t+1) \sim \mbox{Bern}( \phi_t z(i,t)  + \gamma_t (1-z(i,t)) ).
\] 

This parameterization then results in $T-1$ survival and recruitment
parameters.  The main difference here is from the CJS model is that we
are now including recruitment and we are interested in estimating $N$.
Since this state model described above is conditional-on-N, we must
deal with the fact that N is unknown, which again is done through data
augmentation.


\subsection{Data Augmentation for the Jolly-Seber Model}

The fundamental challenge in carrying out inference under this model
is that the parameter $N$ (the total number of individuals alive
during at least 1 time period) is not known.  We have discussed and
demonstrated data augmentation in many previous chapters; however,
with the open population model, we have to take care that two issues
are addressed: 1. the data augmentation is large enough to accommodate
all potential individuals alive in the population during the entire
study and 2. that individuals cannot die and then re-enter the
population.  To begin, let's consider the role of $\gamma$ in the
model.

Data augmentation formally reparameterizes the model, replacing $N$,
the number of individuals ever alive with the parameter $\psi$ which
is interpretable as the population size expressed as a fraction of
$M$.  That is, the expected value of $N$ under the model is equal to
$\psi M$.  As a result of this repararameterization, the recruitment
parameters $\gamma_{t}$ are also relative to the number of ``available
recruits'' on the data augmented list of size $M$, and not directly
related to the population size.  This is easily resolved by deriving
$N_t$, and $R_{t}$, the population size and number of recruits in year
$t$, as a function of the latent state variables $z(i,t)$.  In
particular, the total number of individuals alive at time $t$ is
\[
N_{t} = \sum_{i=1}^{M} z(i,t)
\]
and the number of recruits is
\[
R_{t} = \sum_{i=1}^{M} (1-z(i,t-1))z(i,t)
\]
which is the number of individuals {\it not} alive at time $t-1$ but
alive at time $t$.  

In the case of just two primary periods, this process is
straightforward.  When the number of primary sample occasions is
greater than 2, we must formulate the model for recruitment by
introducing another latent variable.  We do this in order to ensure
that an individual can only be recruited once into the population.
Here, this formulation of the model uses a set of latent indicator
variables $r(i,t)$ which describe the time interval $(t-1, t)$ at
which individual is recruited into the population.  Let $r(i,t) = 1$
if individual $i$ is recruited in time interval $(t-1, t)$ otherwise
$r(i,t)=0$.  To construct the recruitment process we make use of the
standard conditional binomial construction of a removal process
(\citealt{royle:book}).  The initial state is given by:
\[
   r(i,1) \sim \mbox{Bin}(1, \gamma_{1})
\]
for $i=1,2,\ldots,N$. Then, for $t>1$
\[
 r(i,t)|r(i, t-1) \dots r(i, 1) \sim \mbox{Bin}((1 - \sum_{\tau=1}^{t-1} r(i, \tau) ) \times \gamma_{t}, 1)
\]
Thus each recruitment variable is conditional on whether it was ever
previously recruited and this construction forces the recruitment
variable after initial recruitment to be degenerate (have a sample
size of 0).  Then, we can describe the state variables $z(i,t)$ by a
1st order Markov process.  For $t=1$, the initial states are fixed:
\[
z(i,1) \equiv r(i,1)
\]
and,
 for subsequent states, we have
\[
z(i,t)|z(i,t\,-\,1),r(i,t)
 \sim \mbox{Bern} (\phi_{t} z(i,t\,-\,1)) \,+ \,  r(i,t).
\]
Thus, if an individual is in the population at time $t$ (i.e., $z(i,t)
= 1$), then that individual's status at time $t+1$ is the outcome of a
Bernoulli random variable with parameter (survival probability)
$\phi_{t}$.  If the individual, however, is not in the population at
time $t$ (i.e., $z(i,t) = 0$), then the outcome is a Bernoulli random
variable with probability $\gamma_{t}$, a parameter that is related to
{\it per capita} recruitment.  We carry out this process in JAGS by
using the \mbox{\tt sum}) and \mbox{\tt step}) functions together to
ascertain if a particular individual $i$ was ever previously alive.
Individuals that were ever previously alive are no longer eligible to
be ``recruited" into the population.



\section{Mist-netting example}

We now return to the ovenbird data collected during a mist-netting
study, and initially presented in Chapter 5.  These data are available
in the \secr package (see, \cite{efford_etal:2004,
  borchers_efford:2008}). To refresh your memory: 44 mist nets spaced
30 m apart on the perimeter of a 600-m x 100-m rectangle (see
fig. XXXX) were operated on 9 or 10 non-consecutive days in late May
and June for 5 years from 2005-2009.

In Chapter 5, we dealt with this dataset as a type of ``multi-season"
model where abundance in each year, $N_{t}$, was estimated
separately. This of course is a first step in thinking about data
collected over multiple years, but now, we can use the JS model to
estimate the demographic processes (survival and recruitment) between
years.  The first issue at hand is that each line in our 3-D array of
data must correspond to a single individual.  Previously, we were not
interested in individual identity across years so this was not of
concern. Now, we must organize the data set so that each row in our
array represents just one individual.  For the ovenbird dataset, we
can organize the data by creating a master list of all individuals
captured during the entire study.  From this list, we can assign each
individual a unique row in our dataset (in the following R commands,
we do this by using the \mbox{\tt unique}) command on the row names
for each year of our 3-D array and use the command \mbox{\tt pmatch})
to associate the data to the correct column).  Additionally, in
Chapter 5 we carried out data augmentation for each year separately;
however, we must consider for example that individuals captured in
year $t$ could have been alive in year $t-1$.  Thus, our data
augmentation must be large enough to include individuals alive during
any of the time periods.  We must set M = 200 now.  For this example,
we hold survival constant but allow recruitment to be time dependent
(since $\gamma$ is essentially a function of the data augmentation
process as described above, it makes sense to allow recruitment to be
time specific).  We demonstrate in the code how to calculate the
number of recruits to the population each year.

\begin{verbatim}

library("secr")
library("scrbook")
library("rjags")
data(ovenbird)

X<-traps<-traps(ovenCH)
xlim<-c(min(X[[1]][,1])-150,max(X[[1]][,1])+150)
ylim<-c(min(X[[1]][,2])-150,max(X[[1]][,2])+150)
ntraps<- nrow(traps[[1]])
Y<-ovenCH
K<-10
M<-200 # do constant data augmentation to all years
Sst<-cbind(runif(M,xlim[1],xlim[2]),runif(M,ylim[1],ylim[2]))
Sst<-array(Sst,dim=c(M,2,5))

birds<- unique(c(unlist(dimnames(Y[[1]])[1]), unlist(dimnames(Y[[2]])[1]), unlist(dimnames(Y[[3]])[1]), unlist(dimnames(Y[[4]])[1]), unlist(dimnames(Y[[5]])[1])))

Yarr<-array(ntraps+1,dim=c(M,K,5))
for(i in 1:5){
tmp<-Y[[i]]
tmp[tmp<0]<-tmp[tmp<0]*(-1) ## one guy died, we ignore that here and treat it as a  normal event
tmp[tmp==0]<-ntraps+1
nind<-nrow(tmp)
nrep<-ncol(tmp)
tmp2<-matrix(ntraps+1,nrow=M,ncol=10)  # pad last col with NA for year 1
tmp2[pmatch(unlist(dimnames(Y[[i]])[1]), birds),1:nrep]<-tmp
Stmp<-Sst[,,i]
Stmp[pmatch(unlist(dimnames(Y[[i]])[1]), birds),1:2]<-spiderplot(tmp2[pmatch(unlist(dimnames(Y[[i]])[1]), birds),1:nrep],as.matrix(X[[i]]))$avg.s   #$
Sst[,,i]<-Stmp
Yarr[,,i]<-tmp2
}


cat("
model {
#PRIORS

psi ~ dunif(0,1)
phi ~ dunif(0,1)
alpha0 ~ dnorm(0,10)
sigma ~dunif(0,200)
alpha1<- 1/(2*sigma*sigma)

A <- ((xlim[2]-xlim[1]))*((ylim[2]-ylim[1]))

for(t in 1:5){
N[t] <- sum(z[1:M,t])
D[t] <- N[t]/A
gamma[t] ~ dunif(0,1)

}

for(i in 1:M){
  z[i,1] ~ dbern(psi)
    #to estimate the number of recruits, we need a few derivations 
  R[i,1]<- z[i,1]
  R[i,2]<-(1-z[i,1])*z[i,2]
  R[i,3]<- (1-z[i,1])*(1-z[i,2])*z[i,3]
  R[i,4] <-(1-z[i,1])*(1-z[i,2])*(1-z[i,3])*(1-z[i,4])*z[i,5]
  R[i,5] <-(1-z[i,1])*(1-z[i,2])*(1-z[i,3])*(1-z[i,4])*z[i,5]
}

  for(t in 1:5){

  S[i,1,t] ~ dunif(xlim[1],xlim[2])
  S[i,2,t] ~ dunif(ylim[1],ylim[2])

  for(j in 1:ntraps){
    d[i,j,t] <- pow(pow(S[i,1,t]-X[j,1],2) + pow(S[i,2,t]-X[j,2],2),1)
     }

  for(k in 1:K){
    for(j in 1:ntraps){
      lp[i,k,j,t] <- exp(alpha0 - alpha1*d[i,j,t])*z[i,t]           
      cp[i,k,j,t] <- lp[i,k,j,t]/(1+sum(lp[i,k,,t]))
    }
    cp[i,k,ntraps+1,t] <- 1-sum(cp[i,k,1:ntraps,t])  # last cell = not captured
    Ycat[i,k,t] ~ dcat(cp[i,k,,t])
  } 
}  

a[i,1]<-(1-z[i,1])

for(t in 2:5){                           #ensure that individuals are not recruited into the population more than once
      a1[i,t] <- sum(z[i, 1:t])          #have you ever been alive (0 = no, >1 = yes)
       a[i,t] <- 1-step(a1[i,t] - 1)     #use the step function to make a1 binary 

       mu[i,t]<- (phi*z[i,t-1]) + (gamma[t]*a[i,t-1])
        z[i,t]~dbern(mu[i,t])
          }
        }

R1<-sum(R[1:M,1])
R2<-sum(R[1:M,2])
R3<-sum(R[1:M,3])
R4<-sum(R[1:M,4])
R5<-sum(R[1:M,5])        
}

",file="modelJS.txt")
###


zst<-c(rep(1,M/2),rep(0,M/2))
zst<-cbind(zst,zst,zst,zst,zst)
inits <- function(){list (z=zst,sigma=runif(1,25,100), gamma=runif(5, 0, 1) ,S=Sst,alpha0=runif(1,-2,-1) ) }             
parameters <- c("psi","alpha0","alpha1","sigma","N","D", "phi", "gamma")  
                                                           
data <- list (X=as.matrix(X[[1]]),K=10,Ycat=Yarr,M=M,ntraps=ntraps,ylim=ylim,xlim=xlim)        

out1 <- jags.model("modelJS.txt", data, inits, n.chains=3, n.adapt=500)
out2JS <- coda.samples(out1,parameters,n.iter=2000)

> summary(out2JS)

Iterations = 2501:22500
Thinning interval = 1 
Number of chains = 3 
Sample size per chain = 20000 

1. Empirical mean and standard deviation for each variable,
   plus standard error of the mean:

             Mean        SD  Naive SE Time-series SE
D[1]    9.135e-05 1.260e-05 5.144e-08      1.082e-07
D[2]    1.047e-04 1.064e-05 4.345e-08      8.867e-08
D[3]    1.108e-04 1.059e-05 4.323e-08      9.387e-08
D[4]    9.694e-05 1.079e-05 4.405e-08      9.948e-08
D[5]    8.095e-05 1.132e-05 4.620e-08      1.060e-07
N[1]    3.171e+01 4.374e+00 1.786e-02      3.754e-02
N[2]    3.636e+01 3.695e+00 1.508e-02      3.078e-02
N[3]    3.846e+01 3.676e+00 1.501e-02      3.259e-02
N[4]    3.365e+01 3.745e+00 1.529e-02      3.453e-02
N[5]    2.810e+01 3.928e+00 1.604e-02      3.680e-02
alpha0 -2.891e+00 1.363e-01 5.564e-04      1.733e-03
alpha1  1.217e-04 1.408e-05 5.749e-08      2.183e-07
gamma   1.100e-01 1.812e-02 7.396e-05      1.590e-04
phi     5.310e-01 5.925e-02 2.419e-04      5.815e-04
psi     1.619e-01 3.367e-02 1.375e-04      2.487e-04
sigma   6.443e+01 3.765e+00 1.537e-02      5.833e-02

2. Quantiles for each variable:

             2.5%        25%        50%        75%      97.5%
D[1]    6.914e-05  8.354e-05  8.930e-05  9.795e-05  0.0001181
D[2]    8.642e-05  9.795e-05  1.037e-04  1.123e-04  0.0001268
D[3]    9.218e-05  1.037e-04  1.095e-04  1.181e-04  0.0001325
D[4]    7.778e-05  8.930e-05  9.507e-05  1.037e-04  0.0001210
D[5]    6.050e-05  7.202e-05  8.066e-05  8.930e-05  0.0001037
N[1]    2.400e+01  2.900e+01  3.100e+01  3.400e+01 41.0000000
N[2]    3.000e+01  3.400e+01  3.600e+01  3.900e+01 44.0000000
N[3]    3.200e+01  3.600e+01  3.800e+01  4.100e+01 46.0000000
N[4]    2.700e+01  3.100e+01  3.300e+01  3.600e+01 42.0000000
N[5]    2.100e+01  2.500e+01  2.800e+01  3.100e+01 36.0000000
alpha0 -3.159e+00 -2.982e+00 -2.890e+00 -2.800e+00 -2.6229336
alpha1  9.560e-05  1.119e-04  1.212e-04  1.309e-04  0.0001506
gamma   7.801e-02  9.732e-02  1.089e-01  1.214e-01  0.1486346
phi     4.148e-01  4.909e-01  5.312e-01  5.713e-01  0.6466406
psi     1.019e-01  1.381e-01  1.596e-01  1.834e-01  0.2336442
sigma   5.762e+01  6.180e+01  6.424e+01  6.684e+01 72.3179358
\end{verbatim}
XXXXX BETH: Can you summarize results maybe to 2 or 3 sig digits only?
(will that work?  Also maybe leave out the ``Quantiles'' summary just
to reduce ethe output. Sometimes we use 95\% confidence intervals
though so if you want to summarize the 95 CIs for key parameters
seperate thats ok too. XXXXX

Our results for density, alpha0, and alpha1 are rather similar to those found in the multi-season analysis from Chapter 5   
XXX Need to run chains longer XXX. Since all of our parameters including alpha0 and alpha1 are shared between seasons, we 
would expect these results to be similar between the multi-season model and the JS model.  However, here we also estimate the 
 recruitment for each year (~XX, update when model finishes) and the posterior mean for survival (phi) to be 0.53.   These results for survival seem pretty 
reasonable when compared with the literature.  Some studies have found annual male ovenbird survival to be around 0.62 \citep
{porneluzi_faaborg:1999, bayne_hobson:2002}; however, female ovenbird survival was much lower (0.21, \cite
{bayne_hobson:2002}). With more individuals, we could run this model with survival estimated for each sex separately.  
However, we should be careful not to over-parameterize our model based on the amount of data that is available.  




\section{Activity Centers}

We extend the model of individual encounter histories by specifying an
additional model component that describes the spatial distribution of
individual activity centers.  A plausible ``null model'' for the
distribution of individual activity centers is to assume they are
static over time, i.e., ${\bf s}_{i} \sim \mbox{Unif}({\cal S})$.  One
of the key demographic parameters to be estimated is the population
density which is equivalent to the density of individual activity
centers in the region ${\cal S}$. Estimation of this quantity is
described in the next section.  While this model is exceptionally
simple, we adopt it in our analysis of the Pampas cat data due to the
sparsity of the data. However, with larger data sets having more
recaptures (and hence more information about individual location) we
could allow the activity center to change across years.  One
possibility is to assume that ${\bf s}(i,t) \sim \mbox{Normal}({\bf
  s}(i,t-1), \tau^{2} {\bf I})$ for $t > 1$ so that individual home range
centers are perturbed randomly from their previous value.  Using such
models we could conceivably test hypotheses about home range dynamics.


\subsection{Multi-year Black Bear Example}

XXX Will fill in shortly XXXX

A 3 year study of black bears was conducted in the upper peninsula of
Michigan.  Researchers placed XX hair snares in an array and checked
them weekly for 6 weeks.  The study was conducted each summer for 3
consecutive years, thus our secondary periods in this example are
weeks and the primary period is years.

\begin{verbatim}

model {

sigma~dunif(0, 10)
sigma2 <- sigma*sigma      # set priors for sigma2, lam0 (encounter rate), gamma, and phi
lam0 ~ dgamma(.1,.1)       

sigY~dunif(0,10)
tauY <- 1/(sigY * sigY)

sigX~dunif(0,10)
tauX <- 1/(sigX * sigX)
    
for(jj in 1:T){             # T = 3 years
    gamma[jj]~dunif(0, 1)   #recruitment
    phi[jj]~dunif(0, 1)     #survival
    N[jj]<-sum(z[1:M,jj])
    }

for (i in 1:M){            #loop over M individuals (includes the augmented data)
      z[i,1] ~ dbin(gamma[1], 1)
    S[i,1,t] ~ dunif(xlim[1],xlim[2])
    S[i,2,t] ~ dunif(ylim[1],ylim[2])

   for(j in 1:J) {    #loop over all traps
       for(t in 1:T){

            d[i,j,t] <- pow(S[i,1,t]-X[j,1],2) + pow(S[i,2,t]-X[j,2],2)
            g[i,j,t] <- lam0*exp(-d[i,j,t]/sigma2)
        pmean[i,j,t] <- 1- exp(-g[i,j,t])
          tmp[i,j,t] <- z[i,t]*pmean[i,j,t]
            y[i,j,t] ~ dbin(tmp[i,j,t], K[j,t])    #K[j,t] is the number of occasions trap j was operational in year t
        }
     }
   
  a[i,1]<-(1-z[i,1])

  for(t in 2:T){
     S[i,1,t] ~ dnorm(S[i,1,t], tauX)
     S[i,2,t] ~ dnorm(S[i,2,t], tauY)

      a1[i,t] <- sum(z[i, 1:t])
       a[i,t] <- 1-step(a1[i,t] - 1)

      mu[i,t]<- (phi[t]*z[i,t-1]) + (gamma[t]*a[i,t-1])
       z[i,t]~dbern(mu[i,t])
          }



R[i,1]<- z[i,1]
R[i,2]<-(1-z[i,1])*z[i,2]
R[i,3]<- (1-z[i,1])*(1-z[i,2])*z[i,3]
}


R1<-sum(R[1:M,1])
R2<-sum(R[1:M,2])
R3<-sum(R[1:M,3])

}
\end{verbatim}


\section{Summary and Outlook}

Activity center dynamics..... A brief survey of the point process
literature to indicate what is out there......

There is a classical paper by Rathbun and Cressie









