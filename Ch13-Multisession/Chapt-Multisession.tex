\chapter{SCR for Stratafied Populations: 
Multi-sesssion and Multi-site Data}
\markboth{Stratified Population Models}{}
\label{chapt.hscr}

\vspace{0.3cm}


In this chapter, we describe SCR models for situations when
we have multiple, distinct groups, strata or ``sessions''
(multi-session models using the \mbox{\tt secr} terminology). The
models are extremely general and provide a flexible hierarchical
modeling framework for modeling abundance \citep{converse_royle:2012,
  royle_etal:2012arXiv}.  We believe that such ``stratified''
populations are extremely commonplace, yet most SCR applications have
been based on models that are distinctly single-population
models. This is done either by analyzing seperate data sets
one-at-a-time or by pooling data from multiple study areas.  A
standard example that arises frequently is that in which multiple
distinct patches (often refuges, parks or reserves) are sampled
independently with the goal of estimating the population size in each
reserve. It makes sense to combine the data together into a single
model that permits the sharing of information about some parameters,
but provides individual estimates of abundance for each land unit.  A
similar situation is that in which a number of replicate trap arrays
are located within a landscape, sometimes for purposes of evaluating
management actions or landscape structure. This is extremely common in studies of small
mammals \citep{converse_etal:2006jwm, converse_etal:2006ea,
  converse_royle:2012}, or in mist-netting of birds
\citep{desante_etal:1995} (BETTER REF HERE WOULD BE
NICE), but there are examples of large-scale monitoring of carnivores
and other species, e.g., tigers \citep{jhala_etal:2011}.


Stratifed or multi-session SCR models are also directly relevant when
the grouping is based on distinct time samples, either periods within
a biological season, or even across years. 
%Even with a single study
%area or trap array, it would be common to conduct multiple samples
%over short intervals, but then repeat sampling again some weeks or
%months later, and perhaps on multiple years.  
Unlike in the case of having spatial strata, with temporally defined
samples, we imagine a fully dynamic, or demographically open, model
that involves survival and recruitment might be suitable. We deal with
those models specifically in Chapt. \ref{chapt.open}.  However, the
stratified (multi-session) models we deal with in this chapter can be
thought of as a primative type of model for open systems, but in which
the populations are assumed to be {\it independent}. Whereas the
underlying model may be one of Markovian dynamics (survival,
recruitment), we could {\it ignore} that dependence for convenience or
perhaps the dynamics are not distinctly estimable because individual
recapture rate is low.


We focus mostly on Bayesian analysis of stratified SCR models using
data augmentation \citep{royle_etal:2012arXiv,royle_converse:2012}. 
The technical modification of data augmentation to deal with such
models is that it is based on a model for the joint distribution of
the stratum-specific population sizes, 
$N_{g}$, {\it conditioned} on their total. This results in a 
multinomial distribution which we can analyze in some generality using data
augmentation.  As a practical matter, specification of this multinomial
distribution for the $N_{g}$ parameters {\it induces} a distribution
for an individual covariate, say $g_{i}$, which is ``group membership''. 
This is extremely handy to analyze by MCMC in the various {\bf BUGS}
engines that you are familiar with by now.

The {\bf R} package \mbox{\tt secr} fits a class of multi-session
models which we have already seen (sec. \ref{mle.sec.multisession})
and we used this class of models to analyze the ovenbird data in
\mbox{\tt secr} (sec. \ref{poisson-mn.sec.ovenbird}). Later in this
chapter we will provide a Bayesian analysis of the ovenbird data in
{\bf BUGS} using an analogous class of models.


\subsection{Dependence -- is it a problem?}

{\bf XXX This should probably go in the body of the text or something XXXX}

In time -- ignoring the dependence of $N_{g}$ probably entails a
little {\it loss} of efficiency but should have no effect on anything.
In space, there might be some individuals shared by multiple groups
and we don't think that should cause any bias or anything, even in
statement of uncertainty. So we view these models as pretty generally
useful and relevant.
A few points worht discussing: If you have grids that are in
relatively close proximity you might want to build a model in which
the total state-space is used in the model. i.e., form the union of
the state-spaces and model that. That will be more computationally
tedious but on the other hand it preserves the real landscape and any
interactions that might be affecting grids simultaneously. 

\section{Data Structure}


We suppose that $g=1,2,\ldots,G$ populations, having sizes $N_{g}$,
state-spaces ${\cal S}_{g}$
are sampled using some
capture-recapture method producing sample sizes of $n_{g}$ unique
individuals and encounters
$y_{ijk}$ for individual $i=1,2,\ldots, \sum_{g=1}^{G} n_{g}$.  Right
now we won't be concerned with the details of every type of
capture-recapture observation model so, for context, keep in mind the
Bernoulli model in which individual and trap-specific encounter
frequencies have a binomial distribution: $y_{ij} \sim
\mbox{Binomial}(K,p_{ij})$.  Let $g_{i}$ be a covariate
(integer-valued, $1, \ldots, G$) indicating the population membership
of individual $i$. This covariate is {\it observed} for the sample of
captured individuals but not for individuals that are not captured.


A key idea that we develop shortly is that 
the assumption of certain models for the collection of abundance variables
$N_{g}$ {\it implies} a specific model for the population membership
variable $g_{i}$.  
Then, the data from all populations can essentially
be pooled, and analyzed as data from a single population with the
appropriate model on $g_{i}$, without having to model the $N_{g}$
parameters {\it directly}. In this way, we can easily build
hierarchical models for stratified populations, using an {\it
  individual} level parameterization of the model. In fact, the ``population
membership'' variable $g_{i}$ is a {\it categorical} type of individual
covariate (Huggins 1989; Alho 1990; Royle 2009).  

To illustrate this data structure, we suppose that a population
comprised of 4 sub-populations is sampled $K=5$ times. Then a
plausible data set has the following structure:
\begin{verbatim}
      individual (i) : 1  2  3  4  5  6  7  8  9 10  
      frequency (y)  : 1  1  3  1  1  2  2  4  1  1
      group (g)      : 1  1  1  2  3  3  3  3  4  4
\end{verbatim}
This data set indicates three individuals were captured in subpopulation 1
(captured 1, 1, and 3 times), a single individual was captured in
population 2, four individuals were captured in population 3, and two
individuals were captured in subpopulation 4.


\section{Multinomial Abundance Models}


We begin with the Poisson case because this model is the 
model commonly used in ecology for modeling count data, and so it
is natural  as a model for the unknown population size parameters.
We assume
\begin{equation}
 N_{s} \sim \mbox{Poisson}(\lambda_{s})
\label{eq.poisson1}
\end{equation}
with
\begin{equation}
\log( \lambda_{s} ) = \beta_{0} + \beta_{1} x(s)
\label{eq.poisson2}
\end{equation}
where $x(s)$ is some measured attribute for population $s$. Under this
Poisson model, by conditioning on the total population size over all
$S$ populations, the $N_{s}$ variables have a multinomial distribution:
\begin{equation}
{\bf N} = (N_{1},\ldots,N_{S}) | \{ N_{T} =
\sum_{s} N_{s} \} \sim \mbox{Multinom}( {\bm \pi} | N_{T}).
\label{eq.mn.N}
\end{equation}
with 
multinomial probabilities $\pi_{s} = \lambda_{s}/\sum_{s} \lambda_{s}$.



To devise a data augmentation scheme for this model of population
size, we  embed the multinomial for $\{ N_{s} \}$ into a
multinomial of the same dimension but with larger, fixed sample size. 
Specifically, we introduce a latent super-population variable $G_{s}$
which we assume has the desired Poisson distribution but with scaled mean:
 $G_{s} \sim \mbox{Poisson}(A \lambda_{s})$ where $A>>1$ where $A$ 
exists (can be chosen) to ensure that $G_{s}$ is arbitrarily larger than $N_{s}$.
Conditional on the total
super-population size $M = \sum_{s} G_{s}$, then  ${\bf G}$ has a
multinomial distribution: 

\begin{equation}
{\bf G}|M \sim \mbox{Multinom}(M;  {\bm \pi} ) 
\label{eq.mn1}
\end{equation}
where $\pi_{s} = \lambda_{s}/\sum_{s} \lambda_{s}$ which are the same
probabilities as for the target multinomial for ${\bf N}$. 
This multinomial model for the super-population sizes $G_{s}$ is
equivalent to the following:
\[
 g_{i} \sim \mbox{Categorical}({\bm \pi} )
\]
for $g_{i}; i=1,2,\ldots, M$.
Given {\bf G} or, equivalently, $g_{i}$, we specify a model for $\{ N_{s}\}$ that differentiates
between ``real'' and ``pseudo-'' individuals by a Bernoulli sampling
model:
\[
 N_{s} \sim \mbox{Binom}(G_{s} , \psi)
\]
where $\psi \sim \mbox{Unif}(0,1)$. Bernoulli sampling preserves the
marginal Poisson assumption (Takemura 1999). That is, $N_{s}$ is
Poisson, unconditional on $G_{s}$ and, also, 
%Specifically, it has mean $\psi A
%\lambda_{s}$ and then also, 
conditional on $N_{T} = \sum_{s} N_{s}$,
${\bf N}$ has a multinomial with probabilities ${\bm \pi}$ and
index $N_{T}$.  Note also that $N_{T} \sim \mbox{Binom}(M, \phi)$
which is consistent with  data augmentation applied to total
population size $N_{T}$. This binomial sampling model can be
represented, equivalently, by the set of Bernoulli variables:
\[
 z_{i} \sim \mbox{Bern}(\psi)
\]
for $i=1,2,\ldots,M$.
%assumption that
%yields a marginal $\mbox{Unif}(0,M)$ prior for $N_{T}$.



The multinomial construction makes it clear that $\psi$ is confounded
with $\exp(\beta_{0})$. By constructing the model
conditional on the total, we lose information about the intercept
$\beta_{0}$, but this is recovered in the data augmentation parameter
$\psi$.  One of these parameters has to be fixed. We can set $\beta_0
= 0$ or else we can fix $\psi$.  The constraint can be specified by
noting that, under the binomial data augmentation model
$E[N_{T}] = \psi M$ and,
under the Poisson model, $E[N_{T}] = \sum_{s} \exp(\beta_{0} + \beta_{1}
x(s))$ and so we can set
\[
 \psi = \frac{1}{M} \sum_{s} \exp(\beta_{0} + \beta_{1} x(s)).
\]
The equivalence of $\psi$ and $\beta_{0}$ can be thought of in terms of pooling data
from the different sub-populations. In a model with {\it no} covariates, 
we could pool 
all of the data and estimate a single parameter $\psi$ or $\beta_0$ but not
both. In this sense, 
 pooling data from multiple spatial samples is justifiable (in terms of
sufficiency arguments) under a Poisson assumption on local abundance
(which was noted by Royle 2004b; Royle and Dorazio 2008, sec. 5.5.1).









\subsection{Implementation}
\label{sec.implementation}

By introducing the latent $G_{s}$ structure, and the Bernoulli
sampling
of $N_{s}$,
the model is equivalently represented by 
the 
latent variable pair $(g_{i},z_{i})$ where $g_{i}$ is categorical
with prior probabilities $\pi_{s}$ and $z_{i} \sim Bern(\psi)$.  
In particular, 
the multinomial assumption for the latent variables $G_{s}$
is formulated in terms of  ``group membership'' for  each individual
in the super-population of size $M$ according to:
\[
 g_{i} \sim \mbox{Categorical}\left( {\bm \pi} \right)
\]
with ${\bm \pi} = (\pi_{1}, \ldots, \pi_{S})$ and $\pi_{s} =  \lambda_{s}/(\sum_{s}
     \lambda_{s})$.
Note that aggregating these $M$
categorical variables yields a set of multinomial variables
consistent with Eq. \ref{eq.mn1}. That is, define 
$G_{1} = \sum_{i=1}^{M} I(g_{i} = 1)$, 
$G_{2} = \sum_{i=1}^{M} I(g_{i} = 2)$, etc., where $I()$ is the
indicator function. 
The binomial sampling from the super-population, 
%$N_{s} \sim \mbox{Binom}(G_{s}, \psi)$
$N_{T} \sim \mbox{Binom}(M, \psi)$
can be described at the level of the individual also, 
 by introducing the binary
variables $z_{1},\ldots,z_{M}$ such that
\[
 z_{i} \sim \mbox{Bern}(\psi)
\]
where $\psi$ is constrained as noted in the previous section. 
We implement this individual-level formulation of the model in BUGS in
Panel \ref{panel.wbcode}.



A second implementation of the model is suggested by working from
Eq. (\ref{eq.mn.N}) -- we can marginalize $N_{T}$
over the prior  $N_{T} \sim \mbox{Binom}(M, \phi)$ to see that 
the  $(S+1) \times 1$ vector 
$(N_{1},\ldots,N_{S},N_{S+1})$ has, conditional on $M$, 
a multinomial distribution 
with cell probabilities
$\pi_{s}^{+} = \pi_{s} \psi$ for $s=1,2,\ldots,S$  and 
 $\pi_{S+1}^{+} = (1-\psi)$ for the last cell which
 corresponds to individuals of the super-population that are not
 members of any of the $S$ populations that were subject to sampling. 
Thus,
\[
{\bf N}|M \sim \mbox{Multinom}({\bm \pi}^{+}).
\]
where the superscript $+$ here indicates that ${\bm \pi}$ is a larger
version of ${\bm \pi}$ from \ref{eq.mn1}.
In this case, 
\begin{equation}
g_{i}  \sim \mbox{Categorical}( {\bm \pi}^{+} ) \mbox{ for
  $i=1,\ldots,M$}  \label{eq.parm1c}
\end{equation}









Conceptually we can apply models like this which assume Ng are
independent even if they're not... as long as we dont cear about the
underlying dynamics explictly and also possibly with some loss of
eficiency. 

GROUPS, STRATA, POPULATIONS, ETC...????


\begin{comment}

We motivate the approach from Royle et al. and Converse and Royle,
etc.. using a 2 population example.

N1 and N2 are two population sizes. We can data augment the two
independently with M1 and M2 being the population sizes.  We imagine
that
N1 ~ bin(M1,psi)
N2 ~ bin(M2,psi)
We could allow psi to vary by population and model covariates in psi
to explain variation in N. In the present case psi could be population
specific and we are fully modeling the variation in population
size. In general, that kind of unconstrained model wouldn't be ideal
b/c too many parameters and its not clear that it does, or the extent
to which it does, honor the Poisson model assumption that we used as a
starting point for the model.

But imagine this: If we assume M1 and M2 are Poisson(lambda) then it
is clear that N1 and N2 are, marginally, iid Poisson(psi*lambda).  But
we know M1 and M@ have to be a lot larger than Ng so lets say M1 and
M2 are Poisson(A*lambda) for a large value of A in which case Ng is
Poisson(psi*A*lambda) so the point here is that by making the data
augmented super populations have the same distribution but with a
scaled mean, we ensure that the marginal for Ng is the desired
distribution. Note we absorb psi into A and just call it psi* and its
just the same data augmentation parameter.  But we can't really
simulate M1 and M2 from ``the right'' Poisson distribution because we
don't, in general, know what the covariatez are that affect
lambda. (for the G=2 case we could just simulate 2 Poissons with huge
mean and it would be ok but once we introduce a covariate in lambda
then we can't simulate the Mg's in the correct ratio because we don't
know the coefficient on the covariate).

Ok so what do we do?
Well if M1 and M2 are Poisson then it is the case that (M1,M2)
conditional on their total is binomial with sample size M1+M2 and
parameter pi. So in a sense the multinomial distribution that is
conditional on the TOTAL augmented super-population size, is
consistent with the target Poisson distribution we want to ensure, but
it is conditional on the total which we do not have to simulate
randomly in the correct ratio.   That is, we only have to choose the
TOTAL augmented population now and not {\it each} population
size. Once we do dthis then, in fact,
N1 = Bin(Mtot, pi*psi)
N2 = Bin(Mtot, (1-pi)*psi)
and they total up to be binomial with Mtot and pi. So the uniform data
augmentation makes these two parameters have binomial distributions
conditional on Mtot which we know is approximately the target Poisson
distribution if Mtot is large and psi is really small. 

In this model, to implement it, we can have our da variables z[i] but
then we have to split each real guy into the 2 groups. To do that we
have g[i] a cateogrical individual effect which has probabilitys
pi[1] = lambda[1]/(lambda[1]+lambda[2])... where is this going?



So the idea is that we work with the binomial model doing a 
``data augmenation on the total'' instead of data augmenting each
population by itself. 

In this case then , in the general case, the Ng are, conditional on
Ntotal, multinomial with probabilities pi(g) = lambda(g)/sum lambda(g).
\end{comment}





\section{Model formulation}

Here we note that Ng conditional on total has a multinomial
distribution. We can implement that with a bunch of categorical
variables which are equivalent to multinomial trials.  The
cateogorical is this:
\[
formula
\]
So this categorical model on a ``stratum membership''

Bernoulli model...................


The thing is this induces a slight bit of {\it dependence} among the
counts but, for even a smallish number of populations , and of
moderate size, the dependence is imperciptable and we think basically
irrelevant from an inference standpoint. 

\subsection{Simulating structured data}

So how to simulate data?


\subsection{Other issues}


\section{Multi-sessions}

The case here is we have $g=1,\ldots,G$ samples over time but
individuals are coming and going.
We might capture some individuals over time but we ignore the
individual recaptures across primary periods. (See chapter
\ref{chapt.open}). So instead of modeling the dynamics at the individual
level we just model net change in $N_{g}$.


\section{What does \mbox{\tt secr} do?}



