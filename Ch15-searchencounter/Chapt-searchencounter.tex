\chapter{Models for  Search-Encounter Data}
\markboth{Search-Encounter}{}
\label{chapt.search-encounter}

\vspace{0.3cm}


In this chapter we discuss models for search-encounter data. These are
models are useful in situations where you get to observe directly the
locations of individuals not biased by trap locations but, rather, by
searching space in some fashion. In most cases both detection
probability and parameters related to movement can be estimable. In
the context of Bayesian analysis, we develop search-encounter models
conditional on movement outcomes, say $u_{ik}$, the location of
individual $i$ during sample occasion $k$.  The models we
differentiate here depend on a number of things related to data
structure or protocol -- basically whether or not we record the exact
location and how we record it.

How exactly are these different from models for data from fixed
arrays?  (1) sample units are either continuous space polygons or
lines, not points; (2) we have location information that is not biased
by trap locations (but is biased by the observation device somehow);
(3) because we have direct observations of location that exist
independent of traps we can often build an explicit model of space
usage or an explicit movement model.

A few distinct types of situations exist where these models come in
handy. The prototypical, maybe ideal, situation \citet{royle_etal:2011mee}, is where we have a
single search path through a region of space from which observations are made
(just as in the typical distance sampling situation, using a
transect). As we walk along the search path, 
 we note the location of each individual that is detected, 
{\it and their identity} (this is different from distance
sampling int hat sense). Alternatively, we could delineate a search
area, and conduct a systematic search of that region.
An example is that of \citet{royle_young:2008}, which 
involved a plot search for lizards. They assumed the plot was
uniformly searched which justified an assumption of constant $p$
within the plot boundaries. The data set was $\ge 1$ location
observations for each of a sample of $n$ individuals.  The recent
paper by \citet{efford:2011} discussed likelihood analysis of similar
models. In the terminology 
of \mbox{\tt secr} such models are referred to
as models for {\it polygon detectors}.  The model 
described by \citep{royle_etal:2011mee} is a generalization of the
polygon search model, as we describe below.

Search-encounter models also provide something of a bridge between the
standard models for fixed trap arrays (e.g., Chapt. \ref{chapt.scr0}),
and the models of \citep{chandler_royle:2012} where no individual
identity is present. The latter are search-encounter models where the
movement process (and outcomes) are completely latent. Another type of
model is SCR/DS -- this is a SCR model with ..................

\section{Search-encounter sampling designs}

Before we discuss modeling search-encounter data, we're going to
discuss a little bit about the types of sampling situations that
produce location data.  We imagine there are a lot more situations
than identified here, but these are some of those which we have
encountered over the last few years in developing applications of SCR
models. 
For our purposes here we recognize 4 basic sampling designs, each of
which might have variations due to modification of the basic sampling
protocol. In later sections of this chapter we will do some examples
of some of these.

\subsection{Design 1: Fixed Search Path}

The ideal situation is where we have a continuous search-path or
lines, or multiple such lines, in some region
(Fig. \ref{fig.snakeline}). This is the type of problem described by
\citet{royle_etal:2011mee}. We assume the path or lines are laid out a
priori in some manner that is done independent of the activity centers
of individuals and the collection of data does not affect the
lines. Sometimes the lines are within well-defined polygons (shown in
Fig. \ref{fig.snakeline}) but the polygon boundaries may or may not be
meaningful in terms of the observation process. That is, if one is
sampling along the path shown in Fig. \ref{fig.snakeline} and
recording locations of individuals, then the boundary is not relevant
if individual locations may be recorded outside the polygon
boundary. In this case, perhaps the polygon boundary (quadrats in
Fig. \ref{fig.snakeline}) was used as a mechanism for producing the
transect, but does not affect the collection of data.  A number of
variations of the data collection protocol are possible:

\begin{itemize}
 \item[] Protocol (1a) has us just record the locations of individuals
 \item[] Protocol (1b) has us record location of individuals AND
   location on the transect where we observed the individual
 \item[] Protocol (1c) has us record neither of those things, instead
   we record the closest perpendicular distance. This is a typical
   distance sampling situation which produces exactly a DS type of a
   model (or a CR-DS model). We don't recommend recording closest
   perpendicular distance and we don't discuss these models too much
   here
 \item[] Protocol (1d). In this case, observations are restricted to
   the line itself. We imagine that the line is evolving in response
   to search activity. It is not quite like the other ones so let's
   call it ``ad hoc''. In this case we use small bins as traps and the
   length of the line in each grid as a covariate. Unstructured survey
   data. Thompson et al. and Russell et al.
 \end{itemize}


\begin{figure}
\centering
\includegraphics[width=4in,height=4in]{Ch15-searchencounter/figs/snakeline.png}
\caption{snake line.... showing design 1. more here.
}
\label{searchencounter.fig.snakeline}
\end{figure}



\subsection{Design 2: Uniform search intensity} 

 In this case we
have one or more well-defined sample areas (polygons), such as a
quadrat or a transect, and we imagine that the area is uniformly
searched so that $p = p_0$ is constant within the search area.
Sampling produces locations of individuals within the well-defined
boundaries of the sample area. The polygon boundaries defining the
sample unit are important because it tells us that $p=0$ by design
outside of the boundary.

Using the example from the Fig. \ref{fig.snakeline}, we could imagine that each
quadrat was uniformly searched. The individual quadrat boundaries are
irrelevant and we only need to be concerned about the ``total''
boundary of the composite polygon (the intersection of all little
ones). That said, for analysis in {\bf BUGS}, it is easier to work with square
polygons.  We show a simulation example here and we analyze it either
using a bivariate normal movement model or else a 2-d random walk type
of model.  But we don't provide a real example as \citet{royle_dorazio:2008}
did a reanalysis of the lizard data and see also
\citet{efford:2011ecol} and \citet{marques_etal:2011}.


\subsection{ Design 3: Ad hoc implementation of 1 or 2} 

This is not a formal (i.e., intentional) design but, rather, we
imagine that we set up 
search polygons (e.g., the grid cells in Fig. \ref{fig.snakeline}) and
record 
locations of encountered individuals, but we do not do a uniform search
of quadrats and we neglect to record the GPS path.  

{\bf XXXX Move this material XXXXX}

For analysis of data from such a design, 
we imagine that we can assume a uniform search intensity here
and maybe it won't be so bad.  We should do a simulation study of this
somehow. I am working on methods to lay down some standard sets of
lines for simulating data, and then ignoring the lines in doing an
analysis.  Alternative 2 for analysis: We could map each location to
the CENTER of the grid cell and pretend this is trap array (traps at
center of each grid). This was the idea of Kery et al. and some other
papers.


\subsection{Design 4: Really bad implementation of 1 or 2} 

In this
case we screw up even further and forget to record the locations of
individuals within a bunch of quadrats. 
There are two variations of Design 4:
\begin{itemize}
\item[] Protocol (4a) - We imagine that you could have
counts BY individual identity within each quadrat. Not sure what
analysis model this would be.
\item[] Protocol (4b) - We don't have 
individual identities but just total counts. This is Chandler and
Royle (2012/13).
\end{itemize}


\subsection{Examples}

The capricailie example: search of polygons -- could be search
encounter with uniform search intensity but we ignored the polygon
boundaries and just mapped each observation to the center point.  The
fisher data: we had a GPS line but it was not really fixed , it
evolved as dogs searched around. Therefore as a practical matter the
locations of samples were all {\it on} the line. We therefore mapped
to a center point of a grid. We make a grid of the sampled area and we
assume within each grid if a species is present then it is independent
.... actually if the grid is placed INDEPENDENT of the lines then its
probably safe to make some kind of independence assumption.  Russell
et al. -- similar situation, they have a search parth but not really
independent.

For the rest of this chapter, we will provide some model
formulations for some cases, provide code for simulating and analyzing
the data, and some real examples but not for every situation. 
A number of published examples have been given. The Royle et al. 2011
paper on the MHB. The Royle and Young 2008 (see also Marques et
al. and Efford 2011). We also have the Thompson et al. XXX and Russell
et al. XXXX and Capricaillie paper XXXXX.

Possible examples to provide:

Example 1:  Analysis of the Swiss MHB survey using Design 1

Example 1b: Lizard data. No need to analyze this as it was done in RD book. Mention polygon detectors in secr.

Example 2: Fisher data possibly - lion data or -- or  Capricaillie data?


\section{A Model for Search-Encounter Data}

We focus here on developing a model for Designs 1 and 2, as these
represent an ideal situation.

We describe the model for the encounter data $y_{ik}$ in terms of
individual locations ${\bf u}_{ik}$, the two-dimensional location of
capture at the instant of sample, $k$. In contrast to most of the
models describe in this book, we develop models for encounter
probability that depend explicitly on the instantaneous location ${\bf
  u}_{ik}$, i.e., $p_{ik} \equiv p({\bf u}_{ik}) = \Pr(y_{ik}=1|{\bf
  u}_{ik})$.  Note that ${\bf u}$ is unobserved for the $y=0$
observations and thus we cannot analyze the conditional-on-${\bf u}$
likelihood directly. Instead, we regard ${\bf u}$ as random effects
and assume a distribution for them, which allows us to handle the
problem of missing ${\bf u}_{ik}$ values.

To develop encounter probability models for this problem we cannot
just use the previous models because the ``trap'' is actaully a line
or collection of line segments (e.g., Fig. \ref{fig.snakeline}).
Intuitively, $\Pr(y_{ik}=1|{\bf u}_{ik})$ should increase as ${\bf
  u}_{ik}$ comes ``close'' to the line segments ${\bf X}$. It seems
reasonable to express closeness by some distance metric $|| {\bf
  u}_{ik} - {\bf X} || = dist( {\bf u}_{ik}, {\bf X})$ and then assume
\[
\mbox{logit}(p_{ik}) = \alpha_{0} + \alpha_{1} || {\bf u}_{ik} - {\bf X} ||.
\]
For the case where ${\bf X}$ describes a wandering line, some
kind of average distance from ${\bf u}$ to the line
might be reasonable; possible alternatives include the absolute
minimum distance or the mean over specific segments
of the line (within some distance), etc. 

\subsection{Modeling total hazard to encounter}

Because the line {\bf X} is not a single point (like a camera trap) we
have to somehow describe the total encounter probability to the
line. A natural approach is to model the total hazard to capture
\citep{borchers_efford:2008}, which is standard in survival analysis,
and also distance sampling \citep{hayes_buckland:1983,
  skaug_schweder:1999}.  The individual is detected (analogous to
mortality) if encountered at any point along ${\bf X}$. Naturally,
covariates are modeled as affecting the hazard rate and we think of
distance to the line as a covariate acting on the hazard. Let $h({\bf
  u}_{ik},{\bf x})$ be the hazard of individual $i$ being encountered
by sampling at a point ${\bf x}$ on occasion $t$.  For example, one
possible model assumes, for all points ${\bf x} \in {\bf X}$,
\begin{equation}
\log(h({\bf u}_{ik},{\bf x})) = \alpha_{0} + \alpha_{1}*dist({\bf u}_{ik},{\bf x}).
\label{eq.hazard}
\end{equation}
The total hazard to encounter anywhere along the survey path, for an
individual located at ${\bf u}_{ik}$, say $H({\bf u}_{ik})$, is
obtained by integrating over the surveyed line, which we will evaluate
numerically by a discrete sum where the hazard is evaluated at the set
of points ${\bf x}_{j}$ along the surveyed path:
\begin{equation}
H({\bf u}_{ik}) =  \exp(\alpha_{0}) \left\{ \sum_{x_{j}}  \exp(\alpha_{1}*dist({\bf
    u}_{ik},{\bf x}_{j})) \right\}
\label{eq.totalhazard}
\end{equation}
where ${\bf x}_{j}$ is the $j^{th}$ row of ${\bf X}$ defining the
survey path as a collection of line segments which can be arbitrarily
dense, but should be regularly spaced.  Then the probability of
encounter is
\begin{equation}
p_{it} \equiv p({\bf u}_{it}) = 1- \exp(-H({\bf u}_{it})).
\label{search-encounter.eq.encounterprob}
\end{equation}

This is a reasonably intuitive type of encounter probability model in
that the probability of encounter is large when an individual's
location ${\bf u}_{it}$ is close to the line in the average sense
defined by Eq. (\ref{eq.totalhazard}), and vice versa. Note that
$p_{it}$ also depends on the sample path ${\bf X}$, i.e., $p({\bf
  u}_{it}, {\bf X})$ which we suppress in our notation because ${\bf
  X}$ is fixed for any specific analysis.  We note that we don't
require all line segments are surveyed during each sample period, as
this simply affects the construction of the encounter probability $p$
for each sample. Thus, different line segments may be surveyed at
different times, which results in considerable flexibility in the
design of a survey. Additional covariates could be included in the
hazard function. For example, in some situations observers might
record weather conditions along the route, time-of-day, effort or
other covariates (K\'{e}ry {\it et al.} 2005).

\begin{verbatim}

This formulation of total hazard and encounter probability assumes
that encounter at each point along the line, ${\bf x}_{j}$, is
independent of each other point. Then, the event that an individual is
encountered {\it at all} is the complement of the event that it is not
encountered {\it anywhere} along the line (see also Hayes and Buckland
1983).  In terms of the survival/hazard analogy, the survival function
is $S({\bf u}_{ik},{\bf x}_{j}) = exp(-h({\bf u}_{ik},{\bf x}_{j}))$
and so the probability that an individual ``survives'' all $J$ points
is $\prod_{j} exp(-h({\bf u}_{ik},{\bf x}_{j}))$ and the encounter
probability is therefore the complement of this, which is precisely
the expression given by Eq. (\ref{eq.encounterprob}).

Consider the case of a single survey point, i.e., ${\bf X} \equiv {\bf
  x}$, which we might think of as a camera trap location.  In this
case note that Eq. (\ref{eq.encounterprob}) is equivalent to
\[
\log(-\log(1-p_{ik})) = \alpha_{0} + \alpha_{1}*dist( {\bf u}_{ik},{\bf x})
\]
which is to say that distance is a covariate on detection that is
linear on the complementary log-log scale, which is similar to the
``trap-specific'' encounter probability of our Bernoulli encounter
probability model (see Chapt. \ref{chapt.scr0}).
The difference is that, here, the relevant distance
is between the ``trap'' (i.e. the survey lines) and the individual's
present location, ${\bf u}_{ik}$, which is observable. On the other
hand, in the context of camera traps, the distance is that between the
trap and a latent variable, ${\bf s}_{i}$, representing an
individual's home range or activity center which is not observed.

Any model for encounter probability can be converted to a hazard model
so that encounter probability based on total hazard can be derived.
Royle et al. 2011 considered a bunch of other hazard models including
that described previously
\[
\log(h({\bf u}_{it},{\bf x})) = \alpha_{0} + \alpha_{1}*dist({\bf u}_{it},{\bf x}).
\]
which is usually called the Gompertz hazard function in survival
analysis, and it is most often written $h(t) = a \exp( b*t)$ in which
case $log(h(t)) = log(a) + b*t$.  Model 2 (squared-distance) is a
quadratic function of distance
\[
\log(h({\bf u}_{it},{\bf x})) = \alpha_{0} + \alpha_{1}*dist({\bf u}_{it},{\bf x})^2.
\]
We've used this model quite a bit in the book, and it implies a
bivariate normal hazard rate model. Model 3 is from Borchers \& Efford
(2008):
\[
h({\bf u}_{it},{\bf x} ) = -log(1 - \mbox{expit}(\alpha_{0})
\exp( \alpha_{1}*dist({\bf u}_{it},{\bf x})^2 ) )
\]
which produces a normal kernel model for {\it probability of
  detection} at the point level. i.e., $\Pr(y=1) = 1-\exp(-h) = h_{0}
\exp( \alpha_{1}*dist({\bf u}_{it},{\bf x})^2 )$ where $h_{0} =
\mbox{expit}(\alpha_{0})$.  Model 4 is
\[
\log(h({\bf u}_{it},{\bf x})) = \alpha_{0} + \alpha_{1}*log(dist({\bf u}_{it},{\bf x}))
\]
which is a Weibull hazard function.
\end{verbatim}



\subsection{Movement model}

We have so far described the model for the encounter data in a manner
that is conditional on the locations ${\bf u}_{ik}$, some of which are
unobserved. That consideration alone justifies the need for a 2nd
level model -- a ``random effects'' distribution -- for the ${\bf
  u}_{ik}$ variables. In addition, biologically we expect that these
variables should be correlated because they correspond to repeated
measures on the same individual.  To develop such a model, we adopt
what is now customary in spatial capture-recapture problems -- we
assume that individuals are characterized by a latent variable, ${\bf
  s}_{i}$, which represents a center of activity or territory or
simply ``home range''. This leads to a natural model for the variables
${\bf u}_{ik}$. In particular, we can now think of ${\bf u}_{ik}$ as
the outcomes of a movement process, conditional on the activity center
${\bf  s}_{i}$. Here we make use of the bivariate normal model (but
see below for alternatives):
\[
 {\bf u}_{ik} | {\bf s}_{i} \sim \mbox{Normal}({\bf s}_{i}, \sigma^{2}{\bf I}),
\]
where ${\bf I}$ is the $2\times 2$ identity matrix.  This is a
primitive model of individual movements about their home range but we
believe it will be adequate in many capture-recapture studies which
are often limited by sparse data.

We adopt our now customary assumption for the activity centers ${\bf s}$:
\[
 {\bf s}_{i} \sim \mbox{Uniform}({\cal S}); \; \; i=1,2,\ldots,N.
\]
The usual considerations apply in specifying the state-space ${\cal
  S}$ -- either choose a large rectangle, or prescribe a habitat mask
to restrict the potential locations of ${\bf s}$.



\subsection{Simulation and analysis in {\bf JAGS}}

Here we will simulate a sample data set that goes with the situation
desccribed in Fig. \ref{fig.snakeline} and then analyze the ddata in
{\bf JAGS}.  We begin by defining the state-space containing all of
the sample boxes in Fig. \ref{fig.snakeline} and a total population
size which here which is going to be 4 individuals per unit quadrat
($1 \times 1$). We use a regular square state-space here for
convenience:
\begin{verbatim}
> xlim <- c(-1, 4)
> ylim <- c(-1, 5)
> perbox <- 4
> N <- 30*perbox   # Total of 30 1x1 quadrats
\end{verbatim}
The line in Fig. \ref{fig.snakeline}  is an irregular mesh of points
obtained by an imperfect manual point-and-clicking operation, which
probably mimics many actual situations including the way in which GPS
points come to us. In order to apply our model we need a regular mesh
of points. We can obtain a regular mesh of points from the irregular
mesh by using 
some functions in the packages \mbox{\tt regos}
and \mbox{\tt sp}, especially the function \mbox{\tt sample.Line}, as follows:
\begin{verbatim}
> library(rgeos)
> library(sp)
> line1 <- source("line1.R")

> line1 <- as.matrix(cbind(line1$value$x,line1$value$y))
> points <- SpatialPoints(line1)

> sLine <- Line(points)
> regpoints <- sample.Line(sLine,250,type="regular")  # Key step! 
\end{verbatim}
Next we set a random number seed and simulate activity centers and set
some model parameters required to simulate encounter history data. 
Note, the commands for doing all of this and plotting the results are given
in the function \mbox{\tt search$\_$encounter1} in the {\bf R} package
\mbox{\tt scrbook} XXXX actually called snakeline.R right now
XXXXXXX. 
In the following commands you can see where the
regular mesh representation of the sample line is extracted from the
\mbox{\tt regpoints} object which we just created:
\begin{verbatim}
set.seed(2013)
sx<-runif(N,xlim[1],xlim[2])
sy<-runif(N,ylim[1],ylim[2])

sigma <-.3
alpha0 <- -.5
alpha1 <- -1/(2*(.2^2))

X <- regpoints@coords
J <- nrow(X)
\end{verbatim}

Next we're going to simulate data. We do this basically in 2 parts:
For each individual in the population and for each of $K$ sample
occasions, we simulate the location of the individual as a bivariate
normal random variable with mean ${\bf s}_i$. Next, we compute the
encounter probability model using
Eq. \ref{search-encounter.eq.encounterprob}, and then retain the
data objects corresponding to individuals that get captured at least 1
time. All of this goes
according to the following commands:
\begin{verbatim}
K<- 5        ## Number of sample occasions 
U<-array(NA,dim=c(N,K,2))  ## Locations
y<-pmat<-matrix(NA,nrow=N,ncol=K)
for(i in 1:N){
  for(k in 1:K){
    U[i,k,]<-c(rnorm(1,sx[i],sigma),rnorm(1,sy[i],sigma))
    dvec <- sqrt( ( U[i,k,1] - X[,1])^2 + (U[i,k,2] - X[,2])^2  )
    loghaz <- alpha0 + alpha1*dvec
    H <- sum(exp(loghaz))
    pmat[i,k] <- 1-exp(-H)
    y[i,k] <- rbinom(1,1,pmat[i,k])
  }
}
Ux<-U[,,1]
Uy<-U[,,2]
Ux[y==0]<-NA
Uy[y==0]<-NA

captured<-apply(y,1,sum)
y<-y[captured>0,]
Ux<-Ux[captured>0,]
Uy<-Uy[captured>0,]
\end{verbatim}

Finally, we 
do the data augmentation and we make up some
starting values for the location coordinates that are missing.  For
these,
we cheat a little bit (for convenience and hopefully to improve the
efficiency of the MCMC
for the simulated data sets) and use the actual activity
center
values. In practice, we might think about using the average of the
observed
locations.
\begin{verbatim}
M<-100
nind<-nrow(y)
y<-rbind(y,matrix(0,nrow=(M-nrow(y)),ncol=ncol(y)))
Namat<-matrix(NA,nrow=(M-nind),ncol=ncol(y))
Ux<-rbind(Ux,Namat)
Uy<-rbind(Uy,Namat)
S<-cbind(runif(M,Xl,Xu),runif(M,Yl,Yu))
for(i in 1:nind){
  S[i,]<-c( mean(Ux[i,],na.rm=TRUE),mean(Uy[i,],na.rm=TRUE))
}
Ux.st<-Ux
Uy.st<-Uy
for(i in 1:M){
Ux.st[i,!is.na(Ux[i,])]<-NA
Uy.st[i,!is.na(Uy[i,])]<-NA
Ux.st[i,is.na(Ux[i,])]<-S[i,1]
Uy.st[i,is.na(Uy[i,])]<-S[i,2]
}
\end{verbatim}

The BUGS model specification is shown in Panel XXXXXXXXXX and to
bundle the data, inits, and farm
all of this stuff out to {\bf JAGS} we execute the following set of
commands:
\begin{verbatim}
stuff right here
\end{verbatim}
and this produces the output here:


\begin{verbatim}
> wbout
Inference for Bugs model at "model0.txt", fit using jags,
 3 chains, each with 5000 iterations (first 1000 discarded)
 n.sims = 12000 iterations saved
         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
N         94.448   5.237  81.000  92.000  96.000  98.000 100.000 1.006   520
beta0     -0.539   0.743  -1.714  -1.072  -0.637  -0.102   1.258 1.042    54
beta1    -11.943   2.196 -17.229 -13.236 -11.665 -10.375  -8.378 1.035    62
psi        0.936   0.056   0.792   0.908   0.951   0.979   0.998 1.005   650
sigma      0.340   0.043   0.268   0.309   0.337   0.366   0.436 1.004   820
deviance 206.987  25.474 160.405 189.069 205.779 224.080 259.491 1.017   130

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 319.4 and DIC = 526.3
DIC is an estimate of expected predictive error (lower deviance is better).
\end{verbatim}




\subsection{Hard plot boundaries}

The previous development assumed that encounters can be made anywhere
in space, but that the encounter probability decreases with a summary
of distance from the survey path. In practice, we might delineate a
plot which restricts where individuals might be observed (as in the
situation considered by \citet{royle_young:2008}).  For such cases we
truncate the encounter probability function at the plot boundary,
according to:
\begin{equation}
p({\bf u}_{it}) = (1- \exp(-H({\bf u}_{it}))) \mbox{I}({\bf u}_{it} \in {\cal X})
\label{search-encounter.eq.hardplot}
\end{equation}
where ${\cal X}$ is the surveyed polygon and the indicator function
$\mbox{I}({\bf u}_{it} \in {\cal X}) = 1$ if ${\bf u}_{it} \in {\cal
  X}$ and 0 otherwise.  That is, the probability of encounter is
identically 0 if an individual is located {\it outside} the plot at
sample period $t$.  We demonstrated how to do this in the {\bf BUGS}
language below for a model of uniform search intensity.


\subsection{Analysis of other protocols}


We think there are a number of variations of this basic design that
might arise in practice. 
In the situation elaborated on above, 
the sample path is used to locate individuals and, whether or not an
individual is encountered, is a function of the total hazard to
encounter along the whole line.
A slight variation of this idea (what we called Protocol 1b)
has us record location of individuals and also the location on the 
transect where we observed the individual. 
The probability of encounter is the probability of encounter prior to
point $x_{0}$ on the line (Schweder and Skaug paper? XXXXXX) and there
is a slight modification to the encounter probability model to account
for that. This is exactly a 
 distance-sampling observation model, but with an 
additional hierarchical structure the describes the individual
location scatter about the home range center.
Protocol 1c is a slight variation of this -- instead of recording the
point on the line where the individual was first detected, we use,
instead, the point on the line that has the shortest perpendicular
distance. This is a classical distance sampling observation model, and
it  represents an intentional misspecification of the model
but it seems that the effect of this is relatively minor, or at least
otherwise people wouldn't do it. 

Analysis of 1d is the ``unstructured survey data'' like
from Thompson et al. or Russell et al.  Note also that the capcrap
paper is a version of this - grids or polygons were sampled but no
information on the search path is available. This could be a Design 3
problem but that is excess computation I think.








\section{Design 2: Uniform Search Intensity}

A special case of a search-encounter type of model arises when its
possible to subject a quadrat (or quadrats) to a uniform search
intensity. This could be interpreted as an exhaustive search, or
perhaps just a thorough systematic search of the avaialable habitat. 
The example considered by \citet{royle_young:2008} involved searching
of a 9 ha plot for horned lizards Fig. 
(FIG HERE XXXXXX) by a crew of
several observers. It was felt in that case that complete coverage of
the plot was achieved. In general, however, we think you could have
a random sample of the plot and approximate that as a uniform coverage
-- this is kind of a design-based argument justifying the uniform
search intensity model. (we haven't simulated this situation, but it
would be worth checkign that out).

\begin{figure}
\centering
\includegraphics[width=4.5in,height=3.38in]{Ch15-searchencounter/figs/horny_lizard.jpg}
\caption{A flat-tailed horned lizard.
}
\label{searchencounter.fig.hornylizard}
\end{figure}


Anyhow, it is clear that this uniform search intensity model is a
special case of the more general search encounter model in the sense
that the probabiliyt of encounter of an individual is a constant
$p_{0}$ {\it if} the individual is locatzed in the polygon ${\cal X}$
during sample occasion $k$,  i.e., 
\[
p({\bf u}_{ik}) = p_{0} \mbox{I}({\bf u}_{ik} \in {\cal X})
\]
which resembles Eq. \ref{search-encounter.eq.hardplot}
except replacing the encounter
probability function with constant $p_{0}$. 

In the analysis of \citet{royle_young:2008}, a simple bivariate 
Gaussian movement model was used, in which 
\[
 {\bf u}_{ik} | {\bf s}_{i} \sim \mbox{Normal}({\bf s}_{i}, \sigma^{2}{\bf I}),
\]
However, clearly more general versions of the model can be developed.
For example, imagine a situation where the successive samples of a
bounded sample unit are relatively close together in time so that 
successive locations of individuals are not well-approximated by the
independence model. Naturally we might consider using an
auto-regressive or random-walk type of model in which 
the successive coordinate locations of individual $i$ behave according to:
\begin{eqnarray*}
 u_{1}(i,k) | {\bf s}_{i} &\sim &  \mbox{Normal}( u_{1}(i,k-1),  \sigma^{2}) \\
 u_{2}(i,k) | {\bf s}_{i} &\sim &  \mbox{Normal}( u_{2}(i,k-1),  \sigma^{2}) \\
\end{eqnarray*}
here we use the notation $u_{1}$ and $u_{2}$ for the easting and
northing coordinates, respectively. (to keep from cluttering things up
with too many subscripts we have $i$ and $k$ as parenthetic arguments
here).  At any rate, we can use this model and estimate the parameter
$\sigma$ or even a regression parameter $\rho$ pre-multiplying
the lagged value of $u$ if we wanted to use an AR type specification.  
In the \mbox{\tt scrbook} package, we provide a script for
simulating and fitting search-encounter data using the iid Gaussian
model and also the random walk model.  The {\bf BUGS} model specification
is shown in Panel \ref{search-encounter.panel.uniform} for the random
walk situation.  Of course we imagine that resouorce selection
perhaps using similar ideas to those dexcribed in
Chapt. \ref{chapt.rsf} could be parameterized in this movement model
as well. In this case we set up the run with JAGS using the standard
commands. We did not specific starting valules for the missing
coordinate locations although we imagine that JAGS should perform
better if we provide decent starting values. e.g., the last observed
location or something. 


R CODE FOR SIMULATING THIS SITUATION.....................?

\begin{panel}[htp]
\centering
\rule[0.15in]{\textwidth}{.03in}
{\small
\begin{verbatim}
model{
psi ~ dunif(0,1)
tau ~ dgamma(.1,.1)
p0 ~ dunif(0,1)
sigma.move <- sqrt(1/tau)

# Likelihood 
for (i in 1:M){
  z[i] ~ dbern(psi)
  G[i,1,1] ~ dunif(0,16)
  G[i,1,2] ~ dunif(0,16)

   for (t in 2:n.occasions){
## See here I can only make a model for LOCATION
      G[i,t,1] ~ dnorm(G[i,t-1,1], tau)
      G[i,t,2] ~ dnorm(G[i,t-1,2], tau)
# Test whether the actual location is in- or outside the study area. Needs to be done for each grid cell
    }
   for(t in 1:n.occasions){ 
      inside[i,t] <- step(G[i,t,1]-3) * step(13-G[i,t,1]) *step(G[i,t,2]-3) * step(13-G[i,t,2])
      Y[i,t] ~ dbern(mu2[i,t])
      mu2[i,t] <- p0 * inside[i,t] * z[i]
      } #t
   } #i
N <- sum(z[])
}
\end{verbatim}
}
\rule[-0.15in]{\textwidth}{.03in}
\caption{
{\bf BUGS} model specification for the search-encounter model similar
to Royle and Young 2008 but with a random walk movement model. 
help file \mbox{\tt ?search$\_$encounter} in the {\bf R} package \mbox{\tt scrbook}.
}
\label{search-encounter.panel.uniform}
\end{panel}

\subsection{Movement and Dispersal in Open Populations}

In Chapt. \ref{chapt.open} we discuss many aspects of modeling open
populations, including some aspects of movement. However, given the
introduction of the search-encounter model above, this is celarly
relevant to modeling movement and dispersal in open populations.
In particular, imagine that the model in Panel
\ref{search-encounter.panel.uniform} could be a CJS model ......................
XXXXXXXXXXXXXXXXXXXXXXXX

We condition on the location of first capture, think of this as a CJS
model and introduce a survival parameter $\phi$.....

This model has clear relevance to modeling movement in open systems
including dispersal of individuals. We can include a survival
parameter $\phi$ here.... DO THIS..... cite Schaub and Royle XXXX and
also some other work (Torbjorn's work maybe). 

Modeling dispersal distance directly would be cool.... but we don't
know if that has been done yet.
Idea is you model d and then derive the coordinates .......

the problem is that we observe the coordinates and we cannot specify
the observed data as a deterministic node to the best of our
knkowledge so we haven't figured out a way to deal with this problem
yet. 



\section{ Design 3: Partial Information}

We have seen a number of studies that generate ideal data of a ``Design
1'' type but, for whatever reasons, we choose not to use the search
path information.   We discuss two of these here.
For analysis of this situation, we think there are two options:
you assume the plot was uniformly searched ..........

(1) search path not recorded, locations recorded
(2) search path recorded, locations not recorded
(3) search path not recorded, locations not recorded [but plot of
detection is known]

For (1) you could always assume uniform search intensity , 
which is probably ok if plots were randomly searched.
It would be useful to do a simulation study to look at how bad that
model is if plots were systematically or randomly searched, and with
heterogeneity in search intensity.
For (2), maybe you could map the locations to the center of each plot,
think of the plot as effective traps, and maybe use the search path
length as a covariate, or some measure of coverage of the
plot. Intuitively, this would be a decent solution of the plots are
small relative to typical home range sizes.
For (3) , same thing -- map the locations to the center of the plot,
but now you don't have a covariate of how much effort when into each
plot. 

Variations on this theme have appeared in a number of papers.

\subsection{Capricaillie crap}

In this example, forest stands were searched but we don't actually
have the search path. It was searched in an expert manner and we
think possibly the uniform search intensity model could be
reasonable. 

We provide an example of the Poisson model from
 \citet{mollet_etal:2012}, who obtained a population
size estimate  of a large forest grouse species known as the
capracaillie in a region of Switzerland.

In this study,
8 forest stands  that represent all available habitat of the
species were sampled. Each of the stands was divided into a number of
fragments, each of
sufficient size to sample in a meaningful way, creating 39 patches of around
30-70 ha each. For modeling we further divided each patch roughly in half to
create 78 spatial sample units -- so scat samples could be associated to one of
the 78 sub-units. This was done mostly for the purpose of creating spatial
replicates. If the 39 larger units were used there were relatively little
realized spatial replicates.
We did not use finer scale things because searching was rather opportunistic
and haphazard within a unit. Observers searched out what they thought was
good opportunity to find scats but we don't know the whole extnet of
sampling..........

Importantly, the sample units are actually large forest
patches on the order of tens of ha each, but variable in size. Data
were {\it not} collected by coordinates of observations but rather
just recorded to the specific patch in which the observation was
encountered. To accomodate this we defined ${\bf s}_{i}$ to be a
discrete
random variable taking on values...........................

Forest patches were searched for scat which was
situation in which discrete patches of habitat are searched using some
method and it might be convenient (or occur inadvertently) to
associate samples to the patch level instead of recording observation
locations. In this case we might use a model $s[i] \sim dcat(probs[])$
where $probs[]$ are the probabilities that an individual inhabits a
particular patch.

samples are spatial encounter frequencies of scat essentially and so
it makes sense to think of them as Poisson or other.
In fact there's a bit of opportunistic thinning going on but we'll view
this as random thinning and still asert that the encounter frequencies
are Poisson with constant $\lambda_{0}$ and individual intensity that
depends on distance according to the bivariate normal model.



\begin{figure}
\centering
\includegraphics[width=3.5in,height=3.5in]{Ch15-searchencounter/figs/Cap-fragments.png}
\label{poisson-mn.fig.capfrags}
\caption{Relative size and position of 78 forest fragments sampled for
  capricaillie crap.}
\end{figure}


Each of the 44 units
could be sampled by one person in
one day's work (6-8 hours). Within each unit, we focused our search
for droppings on the areas below roosting trees and feeding trees,
respectively, in hiding sites, along internal forest edges, around
root plates and on tree stumps (cf. Jacob et al. 2010). These habitat
elements are the ones preferred by the birds in winter at a small
spatial scale (Bollmann et al. 2005; Mollet unpublished data).
Five spatial units ($I_a$, $S_a$, $S_b$, $H_a$, $T_a$, Table 2) could
not be sampled because of time constraints (too few days with
favorable weather conditions), resulting in 39 units sampled. For the
same reason, three units $(I_b, W_1, W_a)$ were sampled only
once. Access to the area B (Fig. 2) is possible only in late
spring. In 2009, sampling started on 20 April, and the three units in
area B could be sampled only once (rapid snow melting towards the end
of April precluded repetition of sampling here). All other units were
sampled twice.




\subsection{model}

activity centers were uniformly distributed to each of the 78
fragments in proportion to area of the forest patch within which each
fragment was located.


We parameterized activity centers by a discrete state-space with elements
corresponding to the 8 larger fragments. Moreover, home ranges were allocated
to each fragment in  proportion to area. i.e., we assume
define $\lambda_{frag} = A_{frag} \lambda_{0}$, and then:
\[
 N_{frag} \sim Poisson( A_{frag} \lambda_{0} )
\]
This assumption implies the following prior distribution on ${\bf s}_{i}$ (Chapt.
XYZ; Converse and Royle 2012):
\[
{\bf s}_{i} \sim  \mbox{Categorical}(  \pi_{frag} )
\]
with
\[
 \pi_{frag} = \frac{ \lambda_{frag} }{\sum_{frag} \lambda_{frag}}
\]


Observation model:

Each of the 78 fragments is its own sample unit which we index to the
center point of the fragment. No finer scale information is made about
the observation locations.
Let $y_{ij}$ be  the number of times individual $i$ encountered in stand $j$.
Note these are not unique droppings but rather unique clusters of
droppings because a grouse roosting in a tree might leave a number of
droppings and only one of them was sampled\footnote{perhaps this is
  too optimistic of an assessment?}.



\subsection{Example 2: Fisher study}

Thompson et al. did this fisher study which involved dogs searching
space. This seems typical of many
studies these days -- you have dog teams wander around more or less
opportunistically finding scat.... the seearch path is not laid out a
priori but rather evolves haphazardly.  Strictly speaking it is
somewhat informed by what the dog senses at a very local scale. Maybe
50 m or maybe 100 m, whatever.
So the idea here is to ingore the actual search path information
intentionally and do some spatial aggregation at a scale which we
think is larger than what the dogs are queuing into.......

more details here..... a mpa or whatever....

Mountain lion study...........


\subsection{Tiger analysis}

Arjun's analysis -- trails?




\section{Design 4 -- absence of location information}

We imagine a series of models for situations where we forget
altogether to record location information within the sample unit. We
further assume the design was such that the sample units represent
contiguous quadrats or at least close enough together so that
individuals may be counted in multiple units. The idea here is that by
being exposed to multiple units, there is a spatial dependence induced
and this spatial dependence provides a little bit more of information
about model parameters. 

We have two specific cases here:
Imagine we have a bunch of quadrats or segments that are contiguous
and we do the surveys like above and record counts PER individual  but
no other sampling information. 

The other case is that we don't record individual ID at all -- instead
we just have total count frequencies in each plot. 
This model is precisely the one considered by
\citep{chandler_royle:2012} and this is the focus of Chapt. \ref{chapt.scr-unmarked}.

Comments on inference for the first situation?



\section{Summary and Outlook}

While capture-recapture studies are commonplace in studies of animal
popuatlions,
this includes
the classical notion of capture-recapture based on organized arrays of
traps  but also a large swath of ``designs'' which are more informal,
based on organized or haphazard searches of areas, well-defined or
not. For these situations, sampling is often ad hoc or unstructured in
comparison to normal trapping (e.g., camera trapping) that are based on random
sampling and standardized protocols. 
 In this chapter we showed that SCR models are relevant to these
``unstructured'' sampling problems in the same way as ordinary SCR
data from trap arrays. One of the key conceptual points is that, with
these search-encounter types of designs, the locations of observations
are {\it not} biased by the locations of traps but, rather, locations
of individuals can occur anywhere within search plots or quadrats, or
in the vicinity of a transect or search path. 
Because we can obtain direct observations of location -- outcomes of
movement -- for individuals, it is possible to resolve explicit models
of movement from search-encounter data.
While we only considered the simple case of the independent bivariate
normal movement model, we imagine that many other movement types of
models could be fitted....... random walk , etc...
In this sense, the models are somewhat more general than the standard
SCR models where observations are restricted to a priori fixed
locations.


A key feature of the search encounter models is that they condition
explicitly on ``movement outcomes'', the ${\bf u}_{ik}$ variables,
even though sometimes they might not be observable.
The search-encounter sampling designs usually ............

Searching space for scat is , we imagine, the future of all animal
sampling. 


SCR/DS?