\chapter{Models for  Search-Encounter Data}
\markboth{Search-Encounter}{}
\label{chapt.search-encounter}

\vspace{0.3cm}


In this chapter we discuss models for search-encounter data. These
models are useful in situations where the locations of individuals are
observed directly by searching space in some fashion, rather than
biased by fixed trap locations. In most cases both detection
probability and parameters related to movement can be estimated using
such models. In the context of Bayesian analysis, we develop
search-encounter models conditional on movement outcomes, say
$u_{ik}$, the location of individual $i$ during sample occasion $k$.
The models we differentiate here depend on a number of things related
to data structure or survey protocol -- basically whether or not we
record the exact location and how we record it.

How exactly are search-encounter models different from models for data
from fixed arrays?  (1) sample units are either continuous space
polygons or lines, not points; (2) we have location information that
is not biased by trap locations (that is, restricted only to fixed
trap locations); (3) because we have direct observations of location
that exist independent of traps, we can often build an explicit model
of space usage or an explicit movement model.
% XXX RS: Couldn't you add your observation here, that with fixed arrays the movement model and the detection model are confounded? Actually, I think it might be necessary because we talk so much about movement models in the array models that without a little further info here it's not entirely clear why the movement models from search-encounter are different
Conversely, 
 when we have an array of fixed trap locations, the
movement process is completely confounded with the encounter process
because the list of potential observation locations is prescribed, a
priori, indendent of any underlying movement process.

A few distinct types of situations exist where these models come in
handy. The prototypical, maybe ideal, situation
\citet{royle_etal:2011mee} is where we have a single search path
through a region of space from which observations are made (just as in
the typical distance sampling situation, using a transect). As we walk
along the search path, we note the location of each individual that is
detected, {\it and their identity} (this is different from distance
sampling in that sense). 
Alternatively, we could delineate a search
area, and conduct a systematic search of that region. An example is
that of \citet{royle_young:2008}, which involved a plot search for
lizards. They assumed the plot was uniformly searched which justified
an assumption of constant encounter probability, $p$, for all individuals within the plot boundaries. 
The data set
was $\ge 1$ location observations for each of a sample of $n$
individuals.  The recent paper by \citet{efford:2011} discussed
likelihood analysis of similar models. In the terminology of \mbox{\tt
  secr} such models are referred to as models for {\it polygon
  detectors}.  The model described by \citep{royle_etal:2011mee} is a
generalization of the polygon search model, as we describe below.
% XX RS: You also gonna describe the transect model? Might be nice to add, if so. Something like in the other chapters, like, 'in this chapter... blabla'


\begin{comment}
%%## This argument here is basically true, but i'm not sure how to
%%package the idea yet.

Search-encounter models also provide something of a bridge between the
standard models for fixed trap arrays (e.g., Chapt. \ref{chapt.scr0}, etc.),
and the models described in Chapt. \ref{chapt.noID} in which individual
identity is not available. One one hand, in the standard fixed trap
array situation, we observe individual encounter data at each fixed
trap. In the ``no ID'' models, we observe trap-specific encounter
frequencies, but no individual identity. 
Search-encounter models are intermediate
in terms of the structure of the observable data.

\end{comment}


\section{Search-encounter sampling designs}

Before we discuss models for search-encounter data, we'll
introduce the types of sampling situations that
produce individual location data.  We imagine there are a lot more sampling protocols
than identified here, but these are some of the standard situations that we have
encountered over the last few years in developing applications of SCR
models.  For our purposes here we recognize 4 basic sampling designs,
each of which might have variations due to modification of the basic
sampling protocol. In later sections of this chapter we will explore some
examples involving of some of these situations. 

\subsection{Design 1: Fixed Search Path}

The ideal situation is where we have a continuous search-path or
line, or multiple such lines, in some region
(Fig. \ref{searchencounter.fig.snakeline}). This is the type of
problem described by \citet{royle_etal:2011mee}. We assume the paths or
lines are laid out a priori in some manner that is done independent of
the activity centers of individuals and the collection of data does
not affect the lines.  That is, we assume the lines are established
{\it a priori} without consideration of factors that might affect
density. A situation in which this may be violated is when sampling is
based on sniffer dogs. A handler working a team of dogs is usually
letting the dogs ``follow their nose'', and the dogs are adapting to
their own senses as they work the landscape. 
% XX RS: It's hard to imagine how data collection would affect the lines. Do you mean, for example, we don't divert from the pre-set lines because we see some tracks or something?
Sometimes the lines are within well-defined
polygons (shown in Fig. \ref{searchencounter.fig.snakeline}) but the
polygon boundaries may or may not be meaningful in terms of the
observation process. That is, if one is sampling along the path shown
in Fig. \ref{searchencounter.fig.snakeline} and recording locations of
individuals, then the boundary is not relevant if individual locations
may be recorded outside the polygon boundary. In this case, perhaps
the polygon boundary (quadrats in
Fig. \ref{searchencounter.fig.snakeline}) was used as a mechanism for
producing the transect, but does not affect the collection of data.  A
number of variations of this data collection protocol are possible:

% XX RS: The list is not very intuitive. Why7when would we record the location on the transect where we first saw an individual? (1b) And in the CR-DS hybrid, don't wen use the distance to get at the location of the individual? I guess what's not quite clear here is: are these protocolls that lead to different data structures and thus, different models, or are these just different survey techniques to get at the same thing, namely individual locations
\begin{itemize}
 \item[] Protocol (1a) We know the search path and record the locations of individuals.
 \item[] Protocol (1b) We record the location of individuals and
   the location on the transect where we first observed the individual.
 \item[] Protocol (1c) We record
the closest perpendicular distance. This is a typical
   distance sampling situation, and this is a type of hybrid CR-DS model.
 \item[] Protocol (1d). In this case, observations are restricted to
   the line itself. We imagine that the line is evolving in response
   to search activity. It is not quite like the other ones so let's
   call it ``ad hoc''.
 \end{itemize}


\begin{figure}
\centering
\includegraphics[width=4in,height=4in]{Ch15-searchencounter/figs/snakeline.png}
\caption{
A survey line through parts of 7 quadrats in a
  hypothetical landscape. An observer travels the transect and
  identifies individuals in the vicinity of the line, recording their
  identity and location.
}
\label{searchencounter.fig.snakeline}
\end{figure}


\subsection{Design 2: Uniform search intensity}

In this case we
have one or more well-defined sample areas (polygons), such as a
quadrat or a transect, and we imagine that the area is uniformly
searched so that encounter probability is constant for all individuals
within the search area.
Sampling produces locations of individuals within the well-defined
boundaries of the sample area. The polygon boundaries defining the
sample unit are important because it tells us that $p=0$ by design
outside of the boundary.

Using the example from the Fig. \ref{searchencounter.fig.snakeline},
we imagine that each quadrat was uniformly searched which is equivalent to the
assumption that each individual within the boundaries of the search
path has an equal probability of being detected. 
% XX RS: A couple of things here: I would point out that (if I understand that correctly) individuals don't have the same probability of being within the search path, though, because them being  there depends on how far away they live. Otherwise this statement is just a little confusing. The other thing is: it is not really clear if you are referring to the quadrats in the figure and are saying that these were searcher uniformly (not along the line that snakes through the quadrats in the figure, but actually uniformly), or that if you look at how much of the line is in each quadrat, the amount of 'effort' is the same - so search effort is distributed uniformly among the quadrats. I think the confusion might come from talking about area searches (so I am thinking about 2-d space) but then referencing the search path (where I think 1-d). Maybe this section just needs some definitions up front to make things clearer.
In this case, the individual quadrat boundaries are irrelevant and we
only need to be concerned about the ``total'' boundary of the
composite polygon (the intersection of all little ones). That said,
for analysis in {\bf BUGS}, it is easier to work with rectangular
polygons and so, from a practical standpoint, it might be advantageous
to ensure nice rectangular plot boundaries (or else write your own
MCMC algorithm, see Chapt. \ref{chapt.mcmc}).  We show a simulation
example for an area-search model below, and we analyze it both using a
bivariate normal model and a 2-d random walk type of model to describe
animal movement, i.e., the way individual locations $u_{ik}$ are
generated. For further exampels and analyses, we refer you to
\citet{royle_dorazio:2008}, who reanalyzed the lizard data from
\citet{royle_young:2008}, and \citet{efford:2011ecol} and
\citet{marques_etal:2011}.

% XX RS: Would increase axis labels in the figure.

\subsection{Partial Information Designs (3 and 4)}

In practice, we think many situations will arise in which partial
spatial information is available. The data structure and model are
slightly different in these cases.

Design 3: We imagine that search polygons are defined
(e.g., the grid cells in Fig. \ref{searchencounter.fig.snakeline}) and
we record
locations of encountered individuals, but we do not perform a uniform search
of quadrats and we neglect to record the the search path. 
In this case, we don't have direct information on the observation
process -- we are not able to characterize the {\it probability of
  that specific observation} because, in general, it depends on the
precise configuration of the search path.  In this case, while it is
beneficial to have the location of the individual, we do lose some
information by not recording the points in space from which that
individual was detectable. This would be akin to neglecting to record
the trap locations in the standard situation of having a fixed array
of traps. 
% XX RS: It's not entirely clear to me: so we record individual locations, but we don't spread search effort uniformly and have no means of quantifying effort, is that it?I think it would help to be more explicit about why we need the search path, if we have the location of the individual, which is waht we're really interested in.
%% Andy sez: I embellished above. 

% XX RS - later: I understand now, but I think before or while you outline these protocols, it would be important to state what the different pieces are used for (without equations). So if we don't search an entire area, the path is essential because it tells us where we sampled and thus, where we were able to encounter individuals; also, the path locations are needed for the observation-by-distance model, if we want to specify one; and even if we assign detections to, e.g. grid cell centers, the path in each grid cell can tell us somethign about the search effort (analogous to how many days a camera trap was operational); and the locations of individuals are necessary to get at the movement model. Without these definitions it's hard to appreciate the differences in the data structure and they don't become fully clear until the end of section 2
What we have in these situations are
observations of individuals {\it and} the quadrat they were detected in,
but not the final 
% XX RS: final or finer? If final - why final?
scale ``movement'' information. 


Design 4:
In this
we neglect to record the locations of 
individuals within the quadrats.
{\bf XXXX In this case we treat it as an ordinary SCR model XXXXX}
There are variations of this.
\begin{itemize}
\item[] Protocol (4a) - We imagine that you could have
counts BY individual identity within each quadrat.
% XX RS:  '... for example, if scats are collected and genetically assigned to individuals, and for each individual we get a count of scats in each quadrat'
\item[] Protocol (4b) - We don't have
individual identities but just total counts. This is the
\citet{chandler_royle:2013} model (Chapt. \ref{chapt.noID}).
\end{itemize}
It is possible also that we retain the survey line information, which
could possibly be used to identify a covariate of ``coverage'', in order to account for different search effort in each quadrat. 




\begin{comment}
\subsection{Examples}

The capricailie example: search of polygons -- could be search
encounter with uniform search intensity but we ignored the polygon
boundaries and just mapped each observation to the center point.  The
fisher data: we had a GPS line but it was not really fixed , it
evolved as dogs searched around. Therefore as a practical matter the
locations of samples were all {\it on} the line. We therefore mapped
to a center point of a grid. We make a grid of the sampled area and we
assume within each grid if a species is present then it is independent
.... actually if the grid is placed INDEPENDENT of the lines then its
probably safe to make some kind of independence assumption.  Russell
et al. -- similar situation, they have a search parth but not really
independent.

For the rest of this chapter, we will provide some model
formulations for some cases, provide code for simulating and analyzing
the data, and some real examples but not for every situation.
A number of published examples have been given. The Royle et al. 2011
paper on the MHB. The Royle and Young 2008 (see also Marques et
al. and Efford 2011). We also have the Thompson et al. XXX and Russell
et al. XXXX and Capricaillie paper XXXXX.

Possible examples to provide:

Example 1:  Analysis of the Swiss MHB survey using Design 1

Example 1b: Lizard data. No need to analyze this as it was done in RD book. Mention polygon detectors in secr.

Example 2: Fisher data possibly - lion data or -- or  Capricaillie data?
\end{comment}




\section{A Model for Search-Encounter Data}

We focus here on developing a model for Designs 1 and 2, as these
represent ideal sampling situations.  In contrast to most of the models
described in this book (but see Sec. \ref{poisson-mn.sec.acoustic}), we
develop models for encounter probability that depend explicitly on the
instantaneous location ${\bf u}_{ik}$, for individual $i$ at sample
occasion $k$: $p_{ik} \equiv p({\bf u}_{ik}) = \Pr(y_{ik}=1|{\bf
  u}_{ik})$.  Note that ${\bf u}$ is unobserved for the $y=0$
observations and thus we cannot analyze the conditional-on-${\bf u}$
likelihood directly. Instead, we regard ${\bf u}$ as random effects
and assume a distribution for them, which allows us to handle the
problem of missing ${\bf u}_{ik}$ values.
% XX RS: Maybe refer forward to the movement model that achieves this. 

To develop encounter probability models for this problem we cannot
just use the previous models because the ``trap'' is actaully a line
or collection of line segments (e.g.,
Fig. \ref{searchencounter.fig.snakeline}).  Intuitively,
$\Pr(y_{ik}=1|{\bf u}_{ik})$ should increase as ${\bf u}_{ik}$ comes
``close'' to the line segments ${\bf X}$. It seems reasonable to
express closeness by some distance metric $|| {\bf u}_{ik} - {\bf X}
|| = dist( {\bf u}_{ik}, {\bf X})$ and then assume
\[
\mbox{logit}(p_{ik}) = \alpha_{0} + \alpha_{1} || {\bf u}_{ik} - {\bf X} ||.
\]
For the case where ${\bf X}$ describes a wandering line, some
kind of average distance from ${\bf u}$ to the line
might be reasonable; possible alternatives include the absolute
minimum distance or the mean over specific segments
of the line (within some distance), etc.
% XX RS: technically, we could also assume that all individuals within a certain distance from the search path are encountered with equal prob., right?
% This more out of curiosity...

\subsection{Modeling total hazard to encounter}

Because the line {\bf X} is not a single point (like a camera trap) we
have to somehow describe the total encounter probability induced by
the line. A natural approach is to model the total hazard to capture
\citep{borchers_efford:2008}, which is standard in survival analysis,
and also distance sampling \citep{hayes_buckland:1983,
  skaug_schweder:1999}.  The individual is detected (analogous to
mortality) 
% XX RS: How is this analogous to mortality?
if encountered at any point along ${\bf X}$. Naturally,
covariates are modeled as affecting the hazard rate and we think of
distance to the line as a covariate acting on the hazard. Let $h({\bf
  u}_{ik},{\bf x})$ be the hazard of individual $i$ being encountered
by sampling at a point ${\bf x}$ on occasion $t$.  For example, one
possible model assumes, for all points ${\bf x} \in {\bf X}$,
\begin{equation}
\log(h({\bf u}_{ik},{\bf x})) = \alpha_{0} + \alpha_{1}*dist({\bf u}_{ik},{\bf x}).
\label{eq.hazard}
\end{equation}
Additional covariates could be included in the hazard function in the
same way as for any model of encounter probability that we've
discussed previously.  The total hazard to encounter anywhere along
the survey path, for an individual located at ${\bf u}_{ik}$, say
$H({\bf u}_{ik})$, is obtained by integrating over the surveyed line,
which we will evaluate numerically by a discrete sum where the hazard
is evaluated at the set of points ${\bf x}_{j}$ along the surveyed
path:
\begin{equation}
H({\bf u}_{ik}) =  \exp(\alpha_{0}) \left\{ \sum_{x_{j}}  \exp(\alpha_{1}*dist({\bf
    u}_{ik},{\bf x}_{j})) \right\}
\label{eq.totalhazard}
\end{equation}
where ${\bf x}_{j}$ is the $j^{th}$ row of ${\bf X}$ defining the
survey path as a collection of line segments which can be arbitrarily
dense, but should be regularly spaced.  Then the probability of
encounter 
% XX RS: .. on a given occasion? That just made me think... would an occasion here be a repeated survey of the same search path? Might be good to define or discuss what occasions can mean in this context briefly. I geuss it could be a repeat visit, or a visit later in time to a different quadrat?
is
\begin{equation}
p_{it} \equiv p({\bf u}_{it}) = 1- \exp(-H({\bf u}_{it})).
\label{search-encounter.eq.encounterprob}
\end{equation}
% XX RS: pretty sure the indexing above should be {ik}, no?

This is a reasonably intuitive type of encounter probability model in
that the probability of encounter is large when an individual's
location ${\bf u}_{it}$ is close to the line in the average sense
defined by Eq. \ref{eq.totalhazard}, and vice versa.
Further, consider the case of a single survey point, i.e., ${\bf X} \equiv {\bf
  x}$, which we might think of as a camera trap location.  In this
case note that Eq. (\ref{search-encounter.eq.encounterprob}) is equivalent to
\[
\log(-\log(1-p_{ik})) = \alpha_{0} + \alpha_{1}*dist( {\bf u}_{ik},{\bf x})
\]
which is to say that distance is a covariate on detection that is
linear on the complementary log-log scale, which is similar to the
``trap-specific'' encounter probability of our Bernoulli encounter
probability model (see Chapt. \ref{chapt.scr0}).
The difference is that, here, the relevant distance
is between the ``trap'' (i.e. the survey lines) and the individual's
present location, ${\bf u}_{ik}$, which is observable. On the other
hand, in the context of camera traps, the distance is that between the
trap and a latent variable, ${\bf s}_{i}$, representing an
individual's home range or activity center which is not observed.

%Note that
%$p_{it}$ also depends on the sample path ${\bf X}$, i.e., $p({\bf
%  u}_{it}, {\bf X})$ which we suppress in our notation because ${\bf
%  X}$ is fixed for any specific analysis.
%We note that we don't
%require all line segments are surveyed during each sample period, as
%this simply affects the construction of the encounter probability $p$
%for each sample. Thus, different line segments may be surveyed at
%different times, which results in considerable flexibility in the
%design of a survey.

A key assumption of this formulation of the model is that 
encounters at each point along the line, ${\bf x}_{j}$, are
independent of each other point. Then, the event that an individual is
encountered {\it at all} is the complement of the event that it is not
encountered {\it anywhere} along the line (see also Hayes and Buckland
1983).  In terms of the survival/hazard analogy, 
% XX RS: So surviving in this analogy means not being detected? Would state that explicitly, already before when you mention the analogy first, even if you don't give the formula there.
the survival function
is $S({\bf u}_{ik},{\bf x}_{j}) = exp(-h({\bf u}_{ik},{\bf x}_{j}))$
and so the probability that an individual ``survives'' all $J$ points
is $\prod_{j} exp(-h({\bf u}_{ik},{\bf x}_{j}))$ and the encounter
probability is therefore the complement of this, which is precisely
the expression given by Eq. \ref{search-encounter.eq.encounterprob}.


Any model for encounter probability can be converted to a hazard model
so that encounter probability based on total hazard can be derived.
We introduced this model above:
\[
\log(h({\bf u}_{it},{\bf x})) = \alpha_{0} + \alpha_{1}*dist({\bf u}_{it},{\bf x}).
\]
which is usually called the Gompertz hazard function in survival
analysis, and it is most often written as $h(t) = a \exp( b*t)$ in which
case $log(h(t)) = log(a) + b*t$.  
% XX RS: I really don't know anything about these models, so excuse my ignorance... but do these survival models use any kind of covariate (where we use distance)? Here it sounds like they use distance as a covariate, which is not very intuitive...
Model 2 (squared-distance) is a
quadratic function of distance
\[
\log(h({\bf u}_{it},{\bf x})) = \alpha_{0} + \alpha_{1}*dist({\bf u}_{it},{\bf x})^2.
\]
We've used this model quite a bit in the book, and it implies a
bivariate normal hazard rate model. Model 3 is from Borchers \& Efford
(2008):
\[
h({\bf u}_{it},{\bf x} ) = -log(1 - \mbox{expit}(\alpha_{0})
\exp( \alpha_{1}*dist({\bf u}_{it},{\bf x})^2 ) )
\]
which produces a normal kernel model for {\it probability of
  detection} at the point level. i.e., $\Pr(y=1) = 1-\exp(-h) = h_{0}
\exp( \alpha_{1}*dist({\bf u}_{it},{\bf x})^2 )$ where $h_{0} =
\mbox{expit}(\alpha_{0})$.  
% XX RS: Do we define 'expit' somewhere? I don't remember.
Model 4 is
\[
\log(h({\bf u}_{it},{\bf x})) = \alpha_{0} + \alpha_{1}*log(dist({\bf u}_{it},{\bf x}))
\]
which is a Weibull hazard function.



\subsection{Movement model}

We have so far described the model for the encounter data in a manner
that is conditional on the locations ${\bf u}_{ik}$, some of which are
unobserved. Naturally, we should specify a model for these latent
variables -- i.e., a movement model -- so that we could either do a Bayesian analysis by MCMC
\citep{royle_young:2008, royle_etal:2011} or compute the marginal likelihood
\citep{efford:2011}.
To develop such a model, we adopt
what is now customary in SCR models -- we
assume that individuals are characterized by a latent variable, ${\bf
  s}_{i}$, which represents the activity center.
This leads to some natural models
 for the movement outcomes
${\bf u}_{ik}$ conditional on the activity center
${\bf  s}_{i}$. Here we make use of the bivariate normal model (but
see below for alternatives):
\[
 {\bf u}_{ik} | {\bf s}_{i} \sim \mbox{Normal}({\bf s}_{i}, \sigma^{2}{\bf I}),
\]
where ${\bf I}$ is the $2\times 2$ identity matrix.  
% XX RS: In the partial ID chapter we use a different notation for the BVN model; we use \Sigma, and then define that as a 2x2 matrix with 0 and sigma^2.... thinking about it, these two notations are pretty similar... do you think we should point out that they're the same? 
This is a
primitive model of individual movements about their home range but we
believe it will be adequate in many capture-recapture studies which
are often limited by sparse data.

We adopt our default assumption for the activity centers ${\bf s}$:
\[
 {\bf s}_{i} \sim \mbox{Uniform}({\cal S}); \; \; i=1,2,\ldots,N.
\]
The usual considerations apply in specifying the state-space ${\cal
  S}$ -- either choose a large rectangle, or prescribe a habitat mask
to restrict the potential locations of ${\bf s}$.



\subsection{Simulation and analysis in {\bf JAGS}}

Here we will simulate a sample data set that goes with the situation
desccribed in Fig. \ref{searchencounter.fig.snakeline} and then analyze the data in
{\bf JAGS}.  We begin by defining the state-space containing all of
the sample boxes in Fig. \ref{searchencounter.fig.snakeline} and a total population
which is going to be 4 individuals per unit quadrat
($1 \times 1$). We use a regular square state-space here for
convenience:
% XX RS: Either the numbers below are off or you mean a rectangular S
\begin{verbatim}
> xlim <- c(-1, 4)
> ylim <- c(-1, 5)
> perbox <- 4
> N <- 30*perbox   # Total of 30 1x1 quadrats
\end{verbatim}
The line in Fig. \ref{searchencounter.fig.snakeline}  is an irregular mesh of points
obtained by an imperfect manual point-and-clicking operation, which
probably mimics many actual situations including the way in which GPS
points come to us. In order to apply our model we need a regular mesh
of points. We can obtain a regular mesh of points from the irregular
mesh by using
some functions in the packages \mbox{\tt rgeos}
and \mbox{\tt sp}, especially the function \mbox{\tt sample.Line}, as follows:
\begin{verbatim}
> library(rgeos)
> library(sp)
> line1 <- source("line1.R")

> line1 <- as.matrix(cbind(line1$value$x,line1$value$y))
> points <- SpatialPoints(line1)

> sLine <- Line(points)
> regpoints <- sample.Line(sLine,250,type="regular")  # Key step!
\end{verbatim}
Next, we set a random number seed, simulate activity centers and set
some model parameters required to simulate encounter history data.
Note, the commands for doing all of this and plotting the results are given
in the function \mbox{\tt snakeline} in the {\bf R} package
\mbox{\tt scrbook}. 
In the following commands you can see where the
regular mesh representation of the sample line is extracted from the
\mbox{\tt regpoints} object which we just created:
{\small
\begin{verbatim}
set.seed(2013)
sx<-runif(N,xlim[1],xlim[2])
sy<-runif(N,ylim[1],ylim[2])


sigma.move<- .25
sigma<-.15
alpha0<- 0
alpha1<- 1/(2*(sigma^2))

X <- regpoints@coords
J <- nrow(X)
\end{verbatim}
}

Next we're going to simulate data. We do this basically in 2 steps:
For each individual in the population and for each of $K$ sample
occasions, we simulate the location of the individual as a bivariate
normal random variable with mean ${\bf s}_i$ and $\sigma = 0.25$ ({\tt sigma.move} in the code above). Next, we compute the
encounter probability model using
Eq. \ref{search-encounter.eq.encounterprob}, and then retain the
data objects corresponding to individuals that get captured at least once. All of this goes
according to the following commands:
{\small
\begin{verbatim}
K<- 10   ##period study
U<-array(NA,dim=c(N,K,2))
y<-pmat<-matrix(NA,nrow=N,ncol=K)
for(i in 1:N){
for(k in 1:K){
U[i,k,]<-c(rnorm(1,sx[i],sigma.move),rnorm(1,sy[i],sigma.move))
dvec<-     sqrt( ( U[i,k,1] - X[,1])^2 + (U[i,k,2] - X[,2])^2  )
loghaz<- alpha0 - alpha1*dvec*dvec
H<- sum(exp(loghaz))
pmat[i,k]<- 1-exp(-H)
y[i,k]<- rbinom(1,1,pmat[i,k])
}
}
Ux<-U[,,1]
Uy<-U[,,2]
Ux[y==0]<-NA
Uy[y==0]<-NA
\end{verbatim}
}

% XX RS: Maybe say something about the objects, at least U, which holds the locations; and we set U[y==0]<-NA because this is how we pass partially observed data to JAGS. I think that'll make the code more readable. Or bliefly give the names of the R objects in the simulation description before the code. Also, some of the verbatim stuff is set as {\small} and some isn't.

Finally, we do the data augmentation and we make up some starting
values for the location coordinates that are missing. 
 For these, we
cheat a little bit (for convenience and hopefully to improve the
efficiency of the MCMC for the simulated data sets) and use the actual
activity center values. In practice, we might think about using the
average of the observed locations.
{\small
\begin{verbatim}
ncap<-apply(y,1,sum)
y<-y[ncap>0,]
Ux<-Ux[ncap>0,]
Uy<-Uy[ncap>0,]

M<-200
nind<-nrow(y)
y<-rbind(y,matrix(0,nrow=(M-nrow(y)),ncol=ncol(y)))
Namat<-matrix(NA,nrow=(M-nind),ncol=ncol(y))
Ux<-rbind(Ux,Namat)
Uy<-rbind(Uy,Namat)
S<-cbind(runif(M,xlim[1],xlim[2]),runif(M,ylim[1],ylim[2]))
for(i in 1:nind){
S[i,]<-c( mean(Ux[i,],na.rm=TRUE),mean(Uy[i,],na.rm=TRUE))
}
Ux.st<-Ux
Uy.st<-Uy
for(i in 1:M){
Ux.st[i,!is.na(Ux[i,])]<-NA
Uy.st[i,!is.na(Uy[i,])]<-NA
Ux.st[i,is.na(Ux[i,])]<-S[i,1]
Uy.st[i,is.na(Uy[i,])]<-S[i,2]
}
\end{verbatim}
}

The {\bf BUGS} model specification is shown in Panel 
\ref{search-encounter.panel.design1}, although we neglect the standard
steps showing how to 
bundle the data, inits, and farm
all of this stuff out to {\bf JAGS} (see the help file for \mbox{\tt
  snakeline})for the whole script.

% XX RS: I think the 'cat' part has to be deleted in the panel code
\begin{panel}[htp]
\centering
\rule[0.15in]{\textwidth}{.03in}
{\small
\begin{verbatim}
cat("
model {

# Priors
alpha0~dunif(-25,25)
alpha1~dunif(0,25)

lsigma~dunif(-5,5)
sigma.move<-exp(lsigma)
tau<-1/(sigma.move*sigma.move)
psi~dunif(0,1)

# Likelihood
for(i in 1:M){ # Loop over individuals
 z[i]~dbern(psi)
 s[i,1]~dunif(xlim[1],xlim[2])
 s[i,2]~dunif(ylim[1],ylim[2])
 for(k in 1:K){ # Loop over temporal replicates
    u[i,k] ~ dnorm(s[i,1],tau)
    v[i,k] ~ dnorm(s[i,2],tau)
    for(j in 1:J){ # Loop over each point defining line segments
      d[i,k,j]<-  pow(pow(u[i,k]-X[j,1],2) + pow(v[i,k]-X[j,2],2),0.5)
      h[i,k,j]<-exp(alpha0-alpha1*d[i,k,j]*d[i,k,j])
   }
   H[i,k]<-sum(h[i,k,1:J])
   p[i,k]<- z[i]*(1-exp(-H[i,k]))
   y[i,k] ~ dbern(p[i,k])
 }
}

# Derived quantity
N<-sum(z[])
}
\end{verbatim}
}
\rule[-0.15in]{\textwidth}{.03in}
\caption{
{\bf BUGS} model specification for the search-encounter model similar
to ..................XXXXXXXXXXXX
help file \mbox{\tt ?snakeline} in the {\bf R} package \mbox{\tt scrbook}.
}
\label{search-encounter.panel.design1}
\end{panel}


and this produces the output here:

{\bf XXXx Will table-isze final results XXXXX}

\begin{verbatim}
Run with alpha0= 0
running now with alpha0 = -.8 probably that will suck

> wbout2
Inference for Bugs model at "model0.txt", fit using jags,
 3 chains, each with 2000 iterations (first 500 discarded)
 n.sims = 4500 iterations saved
           mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff
N          105.820  14.422  79.000  95.750 105.000 116.000 134.000 1.100    25
alpha0      -0.527   0.363  -1.211  -0.781  -0.532  -0.284   0.222 1.032    79
alpha1      18.301   2.699  13.170  16.371  18.242  20.187  23.603 1.025    87
psi          0.529   0.079   0.380   0.472   0.527   0.583   0.686 1.077    31
sigma.move   0.229   0.012   0.208   0.221   0.228   0.235   0.254 1.111    27
deviance   187.467  26.985 135.281 168.835 187.000 205.549 242.072 1.021   100

For each parameter, n.eff is a crude measure of effective sample size,
and Rhat is the potential scale reduction factor (at convergence, Rhat=1).

DIC info (using the rule, pD = var(deviance)/2)
pD = 357.0 and DIC = 544.4
DIC is an estimate of expected predictive error (lower deviance is better).
\end{verbatim}




\subsection{Hard plot boundaries}

The previous development assumed that locations of individuals can be
observed anywhere in the state-space, determined only by the encounter
probability model as a function of distance from the search path.
However, in many situations, we might delineate a
plot which restricts where individuals might be observed (as in the
situation considered by \citet{royle_young:2008}).  For such cases we
truncate the encounter probability function at the plot boundary,
according to:
\begin{equation}
p({\bf u}_{ik}) = (1- \exp(-H({\bf u}_{ik}))) \mbox{I}({\bf u}_{ik} \in {\cal X})
\label{search-encounter.eq.hardplot}
\end{equation}
where ${\cal X}$ is the surveyed polygon and the indicator function
$\mbox{I}({\bf u}_{ik} \in {\cal X}) = 1$ if ${\bf u}_{ik} \in {\cal
  X}$ and 0 otherwise.  That is, the probability of encounter is
identically 0 if an individual is located {\it outside} the plot at
sample period $t$.  We demonstrated how to do this in the {\bf BUGS}
language below for a model of uniform search intensity (area-search model).



\subsection{Analysis of other protocols}

We think there are a number of variations of this basic design that
might arise in practice.
In the situation elaborated on above,
the sample path is used to locate individuals and, whether or not an
individual is encountered, is a function of the total hazard to
encounter along the whole line.
A slight variation of this idea (what we called Protocol 1b)
has us record location of individuals and also the location on the
transect where we observed the individual.
The probability of encounter is the probability of encounter prior to
point $x_{0}$ on the line
\citep{skaug_schweder:1999}
and there
is a slight modification to the encounter probability model to account
for that. This is exactly a
 distance-sampling observation model, but with an
additional hierarchical structure the describes the individual
location scatter about the home range center.
Protocol 1c is a slight variation of this -- instead of recording the
point on the line where the individual was first detected, we use,
instead, the point on the line that has the shortest perpendicular
distance. This is a classical distance sampling observation model, and
it  represents an intentional misspecification of the model
but it seems that the effect of this is relatively minor, or at least
otherwise people wouldn't do it.

Analysis of Protocol 1d is the ``unstructured survey data'' like
from Thompson et al. or Russell et al. 

(2) Tiger density in the Bandipur tiger reserve:
\citet{gopalaswamy_etal:2012ecol} reported on a study in the Bandipur
tiger reserve in India, where the objective was to obtain a population
size estimate for the reserve based on camera trapping and DNA
sampling of scats.  They had a camera trapping network, a standard
type of passive detector array, and they also had scat searches along
18 scat routes of a total length of 233.2 km. They created 237
segments of approximately 1 km each and used the center points of
these segments as traps. Effectively they mimic the search encounter
design 1 but, here, scats are only obtained along survey routes.
There is an issue of whether sampling along routes produces some kind
of a bias but, generally speaking, tigers aren't producing scats
randomly on the landscape so this is kind of an irrelevant point.



(3) Status of mountain lions in the Blackfoot Mountains of  Montana.
\citet{russell_etal:2012} mountain lions ({\it Puma
  concolor}). Haphazard searching by hunters who would tranquilize
treed lions and extract DNA.
They used 5 km $\times$ 5 km grid cells for binning the encounters,
and the length of the search path in each grid cell as a covariate of
effort that each grid cell was searched.
The model is the Gaussian hazard model with baseline encounter
probability that depended on sex and effort in each grid cell, on the
log scale:
\[
 log(\lambda_{0,ij}) =
\alpha_{0} + \alpha_{2} log(C_{j}) + \alpha_{3} \mbox{Sex}_{i}
\]
Note for grid cells that were not searched, $C_{j} =0$, and those
probabilities were set to 0 in evaluation of the probability of
encounter.







\subsection{Sierra National Forest Fisher Study}

A real example with data and an R script. 

Thompson et al. did this fisher study which involved dogs searching
space. This seems typical of many
studies these days -- you have dog teams wander around more or less
opportunistically finding scat
(see also Russell et al. 2012) .... the seearch path is not laid out a
priori but rather evolves haphazardly.  Strictly speaking it is
somewhat informed by what the dog senses at a very local scale. Maybe
50 m or maybe 100 m, whatever.
So the idea here is to ingore the actual search path information
intentionally and do some spatial aggregation at a scale which we
think is larger than what the dogs are queuing into.......

Thompson et al. divided the region into 1 km polygons,






\section{Design 2: Uniform Search Intensity}

A special case of a search-encounter type of model arises when its
possible to subject a quadrat (or quadrats) to a uniform search
intensity. This could be interpreted as an exhaustive search, or
perhaps just a thorough systematic search of the avaialable habitat.
The example considered by \citet{royle_young:2008} involved searching
of a 9 ha plot for horned lizards Fig.
\ref{searchencounter.fig.hornylizard} by a crew of
several people. It was felt in that case that complete coverage of
the plot was achieved. In general, however, we think you could have
a random sample of the plot and approximate that as a uniform coverage
-- this is kind of a design-based argument justifying the uniform
search intensity model. (we haven't simulated this situation, but it
would be worth checkign that out).

\begin{figure}
\centering
\includegraphics[width=3.6in,height=2.7in]{Ch15-searchencounter/figs/horny_lizard.jpg}
\caption{A flat-tailed horned lizard showing its typical cryptic
  appearance in its native environment.  Detection of flat-tailed
  horned lizards is difficult because they do not run when
  approached. Instead they shuffle under the sand or press down and
  remain motionless as shown in the picture.  The horns are employed
  only as a last resort if the camouflage fails.  {\it Photo credit:
    Kevin and April Young} }
\label{searchencounter.fig.hornylizard}
\end{figure}

It is clear that this uniform search intensity model is a
special case of the more general search encounter model in the sense
that the probability of encounter of an individual is a constant
$p_{0}$ {\it if} the individual is located in the polygon ${\cal X}$
during sample occasion $k$,  i.e.,
\[
p({\bf u}_{ik}) = p_{0} \mbox{I}({\bf u}_{ik} \in {\cal X})
\]
which resembles Eq. \ref{search-encounter.eq.hardplot} except
replacing the encounter probability function with constant $p_{0}$.

In the analysis of \citet{royle_young:2008}, a simple bivariate
Gaussian movement model was used, in which
\[
 {\bf u}_{ik} | {\bf s}_{i} \sim \mbox{Normal}({\bf s}_{i}, \sigma^{2}{\bf I}),
\]
However, clearly more general versions of the model can be developed.
For example, imagine a situation where the successive samples of a
bounded sample polygont are relatively close together in time so that
successive locations of individuals are not well-approximated by the
independence model. Naturally we might consider using an
auto-regressive or random-walk type of model in which
the successive coordinate locations of individual $i$ behave as follows:
\begin{eqnarray*}
 u_{1}(i,k) | u_{1}(i,k-1) &\sim &  \mbox{Normal}( u_{1}(i,k-1),  \sigma^{2}) \\
 u_{2}(i,k) | u_{2}(i,k-1) &\sim &  \mbox{Normal}( u_{2}(i,k-1),  \sigma^{2}) \\
\end{eqnarray*}
here we use the notation $u_{1}$ and $u_{2}$ for the easting and
northing coordinates, respectively. (to keep from cluttering things up
with too many subscripts we have $i$ and $k$ as parenthetic arguments
here).   In addition, we require that the initial locations have a
distribution and, for that, we might being with a simple model such as
the uniformity model:
\[
 {\bf u}(i,1) \sim \mbox{Uniform}({\cal S})
\]
which effectively takes the place of the model for ${\bf s}_{i}$ that
we typically use. Under this model, individuals dont' have an activity
center but, rather, they drift through space more-or-less randomly
based just on their previous location. See \citet{ovaskainen:2004,
ovaskainen:2008}
see also our discussion of a similar model that might
arise in acoustic  surveys (Sec. \ref{poisson-mn.sec.acoustic}).

We could allow for dependent movements about a central location ${\bf
  s}_{i}$ by modifying the model to be an AR(1) or similar type of
model with parameter $\rho$, e.g.,
\begin{eqnarray*}
 u_{1}(i,k) | {\bf s}_{i} &\sim &  \mbox{Normal}( \rho*( u_{1}(i,k-1)
 - s_{1}(i) ),  \sigma^{2}) \\
\end{eqnarray*}
(and similar for coordinate $u_{2}$).

In the \mbox{\tt scrbook} package, we provide a script for
simulating and fitting search-encounter data using the iid Gaussian
model and also the random walk model. We encourage you to adapt these
to fit the AR(1) movement model.   The {\bf BUGS} model specification
is shown in Panel \ref{search-encounter.panel.uniform} for the random
walk situation.  Of course we imagine that resouorce selection
perhaps using similar ideas to those dexcribed in
Chapt. \ref{chapt.rsf} could be parameterized in this movement model
as well. In this case we set up the run with JAGS using the standard
commands. We did not specific starting valules for the missing
coordinate locations although we imagine that JAGS should perform
better if we provide decent starting values. e.g., the last observed
location or something.

\begin{verbatim}
R CODE FOR SIMULATING THIS SITUATION.....................?
\end{verbatim}



\begin{panel}[htp]
\centering
\rule[0.15in]{\textwidth}{.03in}
{\small
\begin{verbatim}
model{
psi ~ dunif(0,1)
tau ~ dgamma(.1,.1)
p0 ~ dunif(0,1)
sigma.move <- sqrt(1/tau)

# Likelihood
for (i in 1:M){
  z[i] ~ dbern(psi)
  G[i,1,1] ~ dunif(0,16)
  G[i,1,2] ~ dunif(0,16)

   for (t in 2:n.occasions){
## See here I can only make a model for LOCATION
      G[i,t,1] ~ dnorm(G[i,t-1,1], tau)
      G[i,t,2] ~ dnorm(G[i,t-1,2], tau)
# Test whether the actual location is in- or outside the study area. Needs to be done for each grid cell
    }
   for(t in 1:n.occasions){
      inside[i,t] <- step(G[i,t,1]-3) * step(13-G[i,t,1]) *step(G[i,t,2]-3) * step(13-G[i,t,2])
      Y[i,t] ~ dbern(mu2[i,t])
      mu2[i,t] <- p0 * inside[i,t] * z[i]
      } #t
   } #i
N <- sum(z[])
}
\end{verbatim}
}
\rule[-0.15in]{\textwidth}{.03in}
\caption{
{\bf BUGS} model specification for the search-encounter model similar
to Royle and Young 2008 but with a random walk movement model.
help file \mbox{\tt ?search$\_$encounter} in the {\bf R} package \mbox{\tt scrbook}.
}
\label{search-encounter.panel.uniform}
\end{panel}

\subsection{Movement and Dispersal in Open Populations}

In Chapt. \ref{chapt.open} we discuss many aspects of modeling open
populations, including some aspects of modeling movement and dispersal
and the relevance of SCR models to these problems. However, given the
introduction of the search-encounter model above, this is celarly
relevant to modeling movement and dispersal in open populations.
In particular, the model described in Panel
\ref{search-encounter.panel.uniform} could easily be adapted to an
open population by conditioning on the first, and introducing a latent
``alive state'' with survival parameter $\phi_{t}$. This would be a
spatial version of the standard CJS model (REF TO CHAPTER 16 HERE).

This model has clear relevance to modeling movement in open systems
including dispersal of individuals. We can include a survival
parameter $\phi$ here.... DO THIS..... cite Schaub and Royle XXXX and
also some other work (Torbjorn's work maybe).

Modeling dispersal distance directly would be cool.... but we don't
know if that has been done yet.
Idea is you model d and then derive the coordinates .......

the problem is that we observe the coordinates and we cannot specify
the observed data as a deterministic node to the best of our
knkowledge so we haven't figured out a way to deal with this problem
yet.



\section{Designs 3 and 4: Partial Information}

We have seen a number of studies that, in an ideal world, would have
generated data of a ``Design
1'' type but, for some practical reason or other reason, the model described
above cannot be used.
 We discuss some of these problems here, which all seem to involve a
 design type 1 but with partial information. We imagine there could be
 3 distinct situations
\begin{itemize}
\item[(a)] search path not recorded, locations recorded
\item[(b)] search path recorded, locations not recorded
\item[(c)] search path not recorded, locations not recorded [but plot of
detection is known]  {\bf Capercaillie}
\end{itemize}

For analysis of these search-encounter designs with partial information,
we think there are a number of options depending on the situation:
For (a) you could always assume uniform search intensity ,
which is probably ok if plots were randomly searched.
It would be useful to do a simulation study to look at how bad that
model is if plots were systematically or randomly searched, and with
heterogeneity in search intensity.
For (b), maybe you could map the locations to the center of each plot,
think of the plot as effective traps, and maybe use the search path
length as a covariate, or some measure of coverage of the
plot. Intuitively, this would be a decent solution of the plots are
small relative to typical home range sizes.
For (c) , same thing -- map the locations to the center of the plot,
but now you don't have a covariate of how much effort when into each
plot.

Variations on this theme have appeared in a number of papers.  (1)
\citet{mollet_etal:2012}, who obtained a population size estimate of a
large forest grouse species known as the capracaillie ({\it Tetrao
  urogallus}) in Switzerland.  The base SCR model is the Poisson model
(Chapt. \ref{chapt.poisson-mn}). Forest stands were searched by
observers for scat, which was analyzed for DNA identification of
individuals.  A total of 78 spatial units of a few ha each were
searched.  In this example, forest stands were searched but the search
path data was not available, only the unit in which each scat was
found.  It was searched in an expert manner, and it was believed that
a uniform search intensity model could be reasonable.  Importantly,
the sample units are actually large forest patches on the order of
tens of ha each, but variable in size. Data were {\it not} collected
by coordinates of observations but rather just recorded to the
specific patch in which the observation was encountered. To accomodate
this we defined ${\bf s}_{i}$ to be a discrete random variable taking
on values.  Forest patches were searched for scat which was situation
in which discrete patches of habitat are searched using some method
and it might be convenient (or occur inadvertently) to associate
samples to the patch level instead of recording observation
locations. In this case we might use a model $s[i] \sim dcat(probs[])$
where $probs[]$ are the probabilities that an individual inhabits a
particular patch.
\begin{comment}
\begin{figure}
\centering
\includegraphics[width=3.5in,height=3.5in]{Ch15-searchencounter/figs/Cap-fragments.png}
\label{poisson-mn.fig.capfrags}
\caption{Relative size and position of 78 forest fragments sampled for
  capricaillie crap.}
\end{figure}
\end{comment}

\begin{figure}
\centering
\includegraphics[width=5in,height=4.21in]{Ch15-searchencounter/figs/capercaillie_lanz.jpg}
\label{searchencounter.fig.capercaillie}
\caption{A male caprcaillie in its typical lekking position,
{\it Photo credit: Michael Lanz, Switzerland}.
}
\end{figure}

A key point of the model is that it assumed a discrete model for the
activity centers: activity centers were uniformly distributed to each
of the 78 fragments in proportion to area of the forest patch within
which each fragment was located.  This is similar to the multi-session
formulation of the model where, in this case, the ``sessions'' are
discrete forest fragments but, unlike the multi-session models above,
the encounters of an individual can occur in multiple sessions.  The
authors assumed that
\[
 N_{frag} \sim Poisson( A_{frag} \lambda_{0} )
\]
which implies (see Chapt. \ref{chapt.hscr}):
\[
{\bf s}_{i} \sim  \mbox{Categorical}(  \pi_{frag} )
\]
with
\[
 \pi_{frag} = \frac{ \lambda_{frag} }{\sum_{frag} \lambda_{frag}}
\]
The oservation model: Each of the 78 fragments is its own sample unit which we index to the
center point of the fragment. No finer scale information is made about
the observation locations.
Let $y_{ij}$ be  the number of times individual $i$ encountered in stand $j$.

\subsection{Design 4 -- absence of location information}

We imagine that models can be developed for
situations where we neglect
altogether to record location information within the sample unit. We
further assume the design was such that the sample units represent
contiguous quadrats or at least close enough together so that
individuals may be counted in multiple units. The idea here is that by
being exposed to multiple units, there is a spatial dependence induced
and this spatial dependence provides a little bit more of information
about model parameters.

We have two specific cases here:
Imagine we have a bunch of quadrats or segments that are contiguous or
in close proximity
and we do the surveys like above and record counts PER individual  but
no other sampling information. An example of this is the capericaillie
paper by Mollet et al.....

The other case is that we don't record individual ID at all -- instead
we just have total count frequencies in each plot.
This model is precisely the one considered by
\citep{chandler_royle:2012} and this is the focus of Chapt. \ref{chapt.scr-unmarked}.





\section{Summary and Outlook}

While capture-recapture studies are commonplace in studies of animal
popuatlions,
this includes
the classical notion of capture-recapture based on organized arrays of
traps  but also a large swath of ``designs'' which are more informal,
based on organized or haphazard searches of areas, well-defined or
not. For these situations, sampling is often ad hoc or unstructured in
comparison to normal trapping (e.g., camera trapping) that are based on random
sampling and standardized protocols.
 In this chapter we showed that SCR models are relevant to these
``unstructured'' sampling problems in the same way as ordinary SCR
data from trap arrays. One of the key conceptual points is that, with
these search-encounter types of designs, the locations of observations
are {\it not} biased by the locations of traps but, rather, locations
of individuals can occur anywhere within search plots or quadrats, or
in the vicinity of a transect or search path.
Because we can obtain direct observations of location -- outcomes of
movement -- for individuals, it is possible to resolve explicit models
of movement from search-encounter data.
While we only considered the simple case of the independent bivariate
normal movement model, we imagine that many other movement types of
models could be fitted....... random walk , etc...
In this sense, the models are somewhat more general than the standard
SCR models where observations are restricted to a priori fixed
locations.


A key feature of the search encounter models is that they condition
explicitly on ``movement outcomes'', the ${\bf u}_{ik}$ variables,
even though sometimes they might not be observable.
The search-encounter sampling designs usually ............

Searching space for scat is , we imagine, the future of all animal
sampling.


SCR/DS?