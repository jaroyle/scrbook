\chapter{
Preface
}
\markboth{Preface}{}
\label{chapt.preface}


Stuff on hierarchical models and how great those are.

Bayesian and likelihood analysis.....

\section{R programming language}




\section{BUGS Language}




\section{R package scrbook}


\section{Organization of This Book}

In the following chapters we develop a comprehensive synthesis and extension of
spatial capture-recapture models.
Roughly the first third of the book is introductory material --
In Chapt. \ref{chapt.glms} we provide the basic analysis tools to understand and
analyze SCR models - namely generalized linear models (GLMs) with random effects, and their
analysis in {\bf R} and {\bf WinBUGS}.  Because SCR models represent extensions of
basic closed population models, we cover ordinary closed population
models in Chapt. \ref{chapt.closed} wherein, along with Chapts. \ref{chapt.scr0} and \ref{chapt.poisson-mn}
\footnote{might ought to put Modeling Encounter Probability
  as chapter 5 instead}, provides the basic introduction
to capture-recapture models and their spatial extension.
We will see that
SCR models are a
conceptual and technical intermediates between the class of models referred to as
model $M_h$, and so-called
individual covariate models.
We develop technical tools for likelihood (Chapt. \ref{chapt.mle})
and Bayesian analysis (Chapt. \ref{chapt.mcmc}).
The middle part of the book expands set of models that we can deal with to include alternative
observation models related to the type of encounter device (Chapt. \ref{chapt.poisson-mn}), models for encounter probability
(Chapt. \ref{chapt.covariates}), [should include search-encounter
models right after Poisson-mn type models?] and provides basic tools
for model fit and selection (Chapt. \ref{chapt.gof}).
[should include the design chapter right here].
Finally in the last third of the book we address more advanced stuff including modeling
space usage in the encounter process (Chapt. \ref{chapt.ecoldist}), modeling state-space covariates, covariates
that affect density, (Chapt. \ref{chapt.state-space}), open population models (Chapt. \ref{chapt.open}),
models that include unmarked individuals either entirely (Chapt. \ref{chapt.scr-unmarked})
or partially marked samples (Chapt. \ref{chapt.partialID}).

In Chapter XXXX We cover a mish-mash of ideas: using telemetry data, multiple encounter methods, alternative
point-process models, and other topics that are useful but that are not fully developed or that we don't have
room for in this book.





\hl{From Ch1b:}

In our experience, students in ecology and even many established
scientists simply cannot separate what they need to do from how to do
it.  They cannot distinguish clearly (either conceptually or actually)
the difference between the model for their data, and the actual
procedure of how to estimate parameters of that model, or make
predictions - ie., how to do the calculations. Sometimes this issue
raises itself in an email from some hapless grad student wondering
``what is the right statistical test for this type of data?''  In a
sense it is this view that drives our approach to developing elements
of this book.

In contemporary statistical ecology, models and methods are sometimes
obscured by named procedures often that are completely uninformative,
the technical details of which hide in obscurity in some black boxes
such as MARK, PRESENCE, DISTANCE, etc., known only by the few
specialist experts in the field. While it is sometimes convenient to
refer to a type or class of models by a name (logistic regression or
even ``model Mh'') in order to emphasize a broad concept or
methodological area, this is only useful if the fundamental
statistical and mathematical structure underlying that name is
clear. As such, we try to focus on model development and keep the
model development distinct from how to combine our data with the model
to produce estimates and so forth. We talk a lot about hypothetical
data we wish we could observe - complete data sets - data sets as if
$N$ were known, etc.. We talk about the model in precise terms and
then break down various ways for analyzing the model either using
likelihood methods or Bayesian methods or some black-box that does one
or the other.

To fit models, we rely heavily on the various implementations of the
{\bf BUGS} language including {\bf WinBUGS} \citep{lunn_etal:2000},
{\bf JAGS} \citep{plummer:2003}
 and {\bf OpenBUGS} \citep{thomas_etal:2006}. We really like
the {\bf BUGS} language, not merely  as a computational device for
fitting models but because it emphasizes
understanding of what the model is and fosters understanding how to
build models - as Kery XYZ XYZ says ``it frees the modeler in you.''  (direct
citation for this would be nice).  However, in addition to using the
{\bf BUGS} language and its various implementations, we also develop our own
{\bf R} code both for doing MCMC
and maximum likelihood, for which we also use the R
package \mbox{\tt secr} \citep{efford:2011}. In addition, we have
created an {\bf R} package to go with this book, \mbox{\tt scrbook},
which contains the data sets, {\bf R} and {\bf BUGS} scripts, and {\bf
  R} code for doing summary analyses, and some likelihood and MCMC
functions written solely in {\bf R}.
